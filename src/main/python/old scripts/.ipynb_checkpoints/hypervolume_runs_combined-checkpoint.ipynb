{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygmo import hypervolume\n",
    "import csv\n",
    "import statistics\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Modified from Pau's code\n",
    "def compute_pareto_front(population):\n",
    "    #print(np.shape(np.array(population)))\n",
    "    #print(population)\n",
    "    pop_size = len(population)\n",
    "    obj_num = 2\n",
    "\n",
    "    domination_counter = [0] * pop_size\n",
    "\n",
    "    for i in range(pop_size):\n",
    "        for j in range(i+1, pop_size):\n",
    "            # check each objective for dominance\n",
    "            dominate = [0] * obj_num\n",
    "            for k in range(obj_num):\n",
    "                if population[i][k] > population[j][k]:\n",
    "                    dominate[k] = 1\n",
    "                elif population[i][k] < population[j][k]:\n",
    "                    dominate[k] = -1\n",
    "            if -1 not in dominate and 1 in dominate:\n",
    "                domination_counter[i] += 1\n",
    "            elif -1 in dominate and 1 not in dominate:\n",
    "                domination_counter[j] += 1\n",
    "\n",
    "    pareto_solutions = []\n",
    "    for i in range(len(domination_counter)):\n",
    "        if domination_counter[i] == 0:\n",
    "            pareto_solutions.append(population[i])\n",
    "    return pareto_solutions\n",
    "\n",
    "def compute_hv(population):\n",
    "    array_archs = np.zeros((len(population), 2))\n",
    "    for i in range(len(population)):\n",
    "        array_archs[i] = population[i]\n",
    "    hv_object = hypervolume(array_archs)\n",
    "    hv = hv_object.compute([1.1,1.1])/1.1**2\n",
    "    return hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Useful functions and parameter defintions\n",
    "nfe_interval = 50\n",
    "\n",
    "def compute_true_objectives(pen_obj1, pen_obj2, feas_score, stab_score, fib_stiff):\n",
    "    pen_fac = 1\n",
    "    if fib_stiff:\n",
    "        pen_fac = 1.5\n",
    "    pen = (np.log10(np.absolute(feas_score)) + np.log10(np.absolute(stab_score)))/2\n",
    "    obj1 = 15*(pen_obj1 + pen_fac*pen)\n",
    "    obj2 = -8500*(pen_obj2 + pen_fac*pen)\n",
    "    return obj1, obj2\n",
    "\n",
    "def get_feasibility_score(feas_array, index):\n",
    "    return feas_array[index]\n",
    "\n",
    "def get_stability_score(stab_array, index):\n",
    "    return stab_array[index]\n",
    "\n",
    "def get_design(design_array, index):\n",
    "    return design_array[index]\n",
    "\n",
    "def find_last_index(val,search_list):\n",
    "    return len(search_list) - search_list[::-1].index(val) - 1\n",
    "\n",
    "def find_closest_index(val,search_list):\n",
    "    val_diff = np.array(search_list) - val\n",
    "    closest_index = np.argmin(np.abs(val_diff))\n",
    "    return closest_index\n",
    "\n",
    "def extract_data_from_csv(fib_stif, algo, init_bias, num_run):\n",
    "    filepath = 'C:\\\\SEAK Lab\\\\SEAK Lab Github\\\\KD3M3\\\\Truss_AOS\\\\result\\\\old data\\\\'\n",
    "    if algo == 'eps_moea':\n",
    "        fileloc = 'Epsilon MOEA Runs\\\\'\n",
    "        if fib_stif:\n",
    "            filename_model = 'Fibre Stiffness code run results\\\\'\n",
    "            if init_bias:\n",
    "                filename = 'Biased Initialization\\\\EpsilonMOEA_emoea' + str(num_run) + '_biasedinit_fibrestiffness_fullpop.csv'\n",
    "            else:\n",
    "                filename = 'Random Initialization\\\\EpsilonMOEA_emoea' + str(num_run) + '_fibrestiffness_fullpop.csv'\n",
    "        else: \n",
    "            filename_model = 'Truss code run results\\\\'\n",
    "            if init_bias:\n",
    "                filename = 'Biased Initialization\\\\EpsilonMOEA_emoea' + str(num_run) + '_biasedinit_trussstiffness_fullpop.csv'\n",
    "            else:\n",
    "                filename = 'Random Initialization\\\\EpsilonMOEA_emoea' + str(num_run) + '_trussstiffness_fullpop.csv'            \n",
    "    elif algo == 'aos_feas_stab_false':\n",
    "        fileloc = 'AOS MOEA Runs\\\\'\n",
    "        filename_model = ''\n",
    "        if fib_stif:\n",
    "            filename = 'Feas and Stab False\\\\Fibre Stiffness code run results\\\\AOSMOEA_constraint_adaptive' + str(num_run) + '_fibrestiffness_fullpop.csv'\n",
    "        else: \n",
    "            filename = 'Feas and Stab False\\\\Truss code run results\\\\AOSMOEA_constraint_adaptive' + str(num_run) + '_trussstiffness_fullpop.csv' \n",
    "    elif algo == 'sc_dnf':\n",
    "        fileloc = 'Soft Constraint Runs\\\\Disjunctive Normal Form Runs\\\\'\n",
    "        if fib_stif:\n",
    "            filename_model = 'Fibre Stiffness code run results\\\\'\n",
    "            filename = 'Biased Initialization\\\\EpsilonMOEA_emoea_dnf' + str(num_run) + '_fibre_biased_feasstab_penalizedfullpop.csv'\n",
    "        else: \n",
    "            filename_model = 'Truss code run results\\\\'\n",
    "            filename = 'Biased Initialization\\\\EpsilonMOEA_emoea_dnf' + str(num_run) + '_truss_biased_feasstab_penalizedfullpop.csv' \n",
    "    elif algo == 'sc_ach':\n",
    "        fileloc = 'Soft Constraint Runs\\\\Adaptive Constraint Handling Runs\\\\'\n",
    "        if fib_stif:\n",
    "            filename_model = 'Fibre Stiffness code run results\\\\'\n",
    "            filename = 'Biased Initialization\\\\EpsilonMOEA_emoea_ach' + str(num_run) + '_fibre_biased_feasstab_penalizedfullpop.csv'\n",
    "        else: \n",
    "            filename_model = 'Truss code run results\\\\'\n",
    "            filename = 'Biased Initialization\\\\EpsilonMOEA_emoea_ach' + str(num_run) + '_truss_biased_feasstab_penalizedfullpop.csv' \n",
    "\n",
    "    full_filepath = filepath + fileloc + filename_model + filename\n",
    "    #print('filename')\n",
    "    #print(filename)\n",
    "    #print('full_filepath')\n",
    "    #print(full_filepath)\n",
    "\n",
    "    with open(full_filepath,newline='') as csvfile:\n",
    "        data = [row for row in csv.reader(csvfile)]\n",
    "        designs_dat = [\"\" for x in range(len(data)-1)]\n",
    "        num_func_evals_dat = np.zeros(len(data)-1)\n",
    "        pen_obj1_dat = np.zeros(len(data)-1)\n",
    "        pen_obj2_dat = np.zeros(len(data)-1)\n",
    "        feas_scores_dat = np.zeros(len(data)-1)\n",
    "        stab_scores_dat = np.zeros(len(data)-1)\n",
    "        valid_count = 0\n",
    "        for x in range(len(data)-1):\n",
    "            data_float = list(map(float,data[x+1][1:]))\n",
    "            if (any(np.isnan(np.array(data_float)))):\n",
    "                continue\n",
    "            designs_dat[valid_count] = data[x+1][0]\n",
    "            num_func_evals_dat[valid_count] = int(data[x+1][1])\n",
    "            pen_obj1_dat[valid_count] = float(data[x+1][2])\n",
    "            pen_obj2_dat[valid_count] = float(data[x+1][3])\n",
    "            feas_scores_dat[valid_count] = float(data[x+1][4])\n",
    "            stab_scores_dat[valid_count] = float(data[x+1][5])\n",
    "            valid_count += 1\n",
    "            \n",
    "    designs = designs_dat[:valid_count]\n",
    "    num_func_evals = num_func_evals_dat[:valid_count]\n",
    "    pen_obj1 = pen_obj1_dat[:valid_count]\n",
    "    pen_obj2 = pen_obj2_dat[:valid_count]\n",
    "    feas_scores =  feas_scores_dat[:valid_count]\n",
    "    stab_scores = stab_scores_dat[:valid_count]\n",
    "            \n",
    "    ## Sort num_fun_evals (and obj1 & obj2, feas and stab scores) in ascending order\n",
    "    n_func_evals = num_func_evals\n",
    "    sort_indices = np.argsort(n_func_evals)\n",
    "    pen_obj1_sorted = list(pen_obj1[sort_indices])\n",
    "    pen_obj2_sorted = list(pen_obj2[sort_indices])\n",
    "    feas_scores_sorted = list(feas_scores[sort_indices])\n",
    "    stab_scores_sorted = list(stab_scores[sort_indices])\n",
    "    true_obj1_sorted = np.zeros(len(pen_obj1))\n",
    "    true_obj2_sorted = np.zeros(len(pen_obj2))\n",
    "\n",
    "    for i in range(len(pen_obj1_sorted)):\n",
    "        obj1_true, obj2_true = compute_true_objectives(pen_obj1_sorted[i], pen_obj2_sorted[i], feas_scores_sorted[i], stab_scores_sorted[i], fib_stif)\n",
    "        true_obj1_sorted[i] = obj1_true\n",
    "        true_obj2_sorted[i] = obj2_true\n",
    "\n",
    "    designs_sorted = []\n",
    "    for i in range(len(sort_indices)):\n",
    "        designs_sorted.append(designs[sort_indices[i]])\n",
    "    \n",
    "    nfe_list_sorted = list(n_func_evals[sort_indices])\n",
    "    \n",
    "    ## Determine normalizing objective scores for true and penalized objectives \n",
    "    max_func_evals = nfe_list_sorted[-1]\n",
    "\n",
    "    obj_normalize_max_fullrun = [np.max(pen_obj1_sorted), np.max(pen_obj2_sorted)]\n",
    "    obj_normalize_min_fullrun = [np.min(pen_obj1_sorted), np.min(pen_obj2_sorted)]\n",
    "\n",
    "    obj_true_normalize_max_fullrun = [np.max(true_obj1_sorted), np.max(true_obj2_sorted)]\n",
    "    obj_true_normalize_min_fullrun = [np.min(true_obj1_sorted), np.min(true_obj2_sorted)]\n",
    "\n",
    "    obj1_normalize_max_afterjump = 0\n",
    "    obj1_normalize_min_afterjump = 0\n",
    "    obj2_normalize_max_afterjump = 0\n",
    "    obj2_normalize_min_afterjump = 0\n",
    "\n",
    "    pareto_front_dict = {}\n",
    "    pareto_front_feas_dict = {}\n",
    "    pareto_front_stab_dict = {}\n",
    "    pareto_front_designs_dict = {}\n",
    "    pareto_front_true_dict = {}\n",
    "    count = 0\n",
    "    pop_size = int(find_last_index(0, nfe_list_sorted))\n",
    "    nfe_jump_recorded = False\n",
    "    jump_nfe = 0\n",
    "\n",
    "    for i in range(0, int(max_func_evals), nfe_interval):\n",
    "        #print('iter = ' + str(i))\n",
    "    \n",
    "        if (i < 100):\n",
    "            nfe_index_current = pop_size\n",
    "        else:\n",
    "            nfe_index_current = find_closest_index(i, nfe_list_sorted)\n",
    "        \n",
    "        nfe_array_current = nfe_list_sorted[:nfe_index_current]\n",
    "        current_population = []\n",
    "        for j in range(len(nfe_array_current)):\n",
    "            current_population.append([pen_obj1_sorted[j], pen_obj2_sorted[j]])\n",
    "\n",
    "        current_pareto_front_all = compute_pareto_front(current_population)\n",
    "        #current_pareto_front = list(set(current_pareto_front_all))\n",
    "        current_pareto_front = np.unique(current_pareto_front_all, axis=0)\n",
    "    \n",
    "        current_pareto_feas_scores = []\n",
    "        current_pareto_stab_scores = []\n",
    "        current_pareto_designs = []\n",
    "        current_pareto_true_obj = []\n",
    "        for pareto_design in current_pareto_front:\n",
    "            design_index = pen_obj1_sorted.index(pareto_design[0])\n",
    "            design_feas_score = get_feasibility_score(feas_scores_sorted, design_index)\n",
    "            design_stab_score = get_stability_score(stab_scores_sorted, design_index)\n",
    "            current_pareto_feas_scores.append(design_feas_score)\n",
    "            current_pareto_stab_scores.append(design_stab_score)\n",
    "            current_pareto_designs.append(get_design(designs_sorted, design_index))\n",
    "            true_obj1, true_obj2 = compute_true_objectives(pareto_design[0], pareto_design[1], design_feas_score, design_stab_score, fib_stif)\n",
    "            current_pareto_true_obj.append([true_obj1, true_obj2])\n",
    "        \n",
    "        pareto_front_dict[i] = current_pareto_front\n",
    "        pareto_front_feas_dict[i] = current_pareto_feas_scores\n",
    "        pareto_front_stab_dict[i] = current_pareto_stab_scores\n",
    "        pareto_front_designs_dict[i] = current_pareto_designs\n",
    "        pareto_front_true_dict[i] = current_pareto_true_obj\n",
    "    \n",
    "        nonzero_feas_scores = True in (feas_score > 0.1 for feas_score in current_pareto_feas_scores)\n",
    "        if (nonzero_feas_scores):\n",
    "            if (not nfe_jump_recorded):\n",
    "                #print('feas scores at nfe_jump')\n",
    "                #print(current_pareto_feas_scores)\n",
    "                #print('jump_nfe')\n",
    "                #print(i)\n",
    "                jump_nfe = i\n",
    "                nfe_jump_recorded = True\n",
    "        \n",
    "            pareto_obj1s = [pareto_design[0] for pareto_design in current_pareto_front]\n",
    "            pareto_obj2s = [pareto_design[1] for pareto_design in current_pareto_front]\n",
    "        \n",
    "            if (np.max(pareto_obj1s) > obj1_normalize_max_afterjump):\n",
    "                obj1_normalize_max_afterjump = np.max(pareto_obj1s)\n",
    "        \n",
    "            if (np.max(pareto_obj2s) > obj2_normalize_max_afterjump):\n",
    "                obj2_normalize_max_afterjump = np.max(pareto_obj2s)\n",
    "        \n",
    "            if (np.min(pareto_obj1s) < obj1_normalize_min_afterjump):\n",
    "                obj1_normalize_min_afterjump = np.min(pareto_obj1s)\n",
    "        \n",
    "            if (np.min(pareto_obj2s) < obj2_normalize_min_afterjump):\n",
    "                obj2_normalize_min_afterjump = np.min(pareto_obj2s)\n",
    "\n",
    "    obj_normalize_max_afterjump = [obj1_normalize_max_afterjump, obj2_normalize_max_afterjump]\n",
    "    obj_normalize_min_afterjump = [obj1_normalize_min_afterjump, obj2_normalize_min_afterjump]\n",
    "    \n",
    "    obj_normalize_fullrun = [obj_normalize_min_fullrun, obj_normalize_max_fullrun]\n",
    "    obj_normalize_afterjump = [obj_normalize_min_afterjump, obj_normalize_max_afterjump]\n",
    "    obj_normalize_true_fullrun = [obj_true_normalize_min_fullrun, obj_true_normalize_max_fullrun]\n",
    "    \n",
    "    #print('obj_normalize_fullrun')\n",
    "    #print(obj_normalize_fullrun)\n",
    "    #print('obj_normalize_afterjump')\n",
    "    #print(obj_normalize_afterjump)\n",
    "    #print('obj_normalize_true_fullrun')\n",
    "    #print(obj_normalize_true_fullrun)\n",
    "    #print('\\n')\n",
    "    \n",
    "    return pareto_front_dict, pareto_front_true_dict, obj_normalize_fullrun, obj_normalize_afterjump, obj_normalize_true_fullrun, jump_nfe, max_func_evals, nfe_jump_recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute hypervolume arrays from csv file locator parameters\n",
    "def compute_hv_arrays_from_csv_data(pf_dict, pf_true_dict, obj_norm_full, obj_norm_afterjump, obj_norm_true_full, nfe_jump, max_fun_evals, nfe_jump_achieved):\n",
    "    obj_norm_min_full = obj_norm_full[0]\n",
    "    obj_norm_max_full = obj_norm_full[1]\n",
    "    obj_norm_min_afterjump = obj_norm_afterjump[0]\n",
    "    obj_norm_max_afterjump = obj_norm_afterjump[1]\n",
    "    obj_norm_true_min_full = obj_norm_true_full[0]\n",
    "    obj_norm_true_max_full = obj_norm_true_full[1]\n",
    "    #print('obj_norm_min_full')\n",
    "    #print(obj_norm_min_full)\n",
    "    #print('obj_norm_max_full')\n",
    "    #print(obj_norm_max_full)\n",
    "    #print('obj_norm_min_afterjump')\n",
    "    #print(obj_norm_min_afterjump)\n",
    "    #print('obj_norm_max_afterjump')\n",
    "    #print(obj_norm_max_afterjump)\n",
    "    #print('obj_norm_true_min_full')\n",
    "    #print(obj_norm_true_min_full)\n",
    "    #print('obj_norm_true_max_full')\n",
    "    #print(obj_norm_true_max_full)\n",
    "    #print('nfe_jump')\n",
    "    #print(nfe_jump)\n",
    "\n",
    "    ## Normalize the pareto front objectives and compute the hypervolume\n",
    "    hypervol_full_dict = []\n",
    "    hypervol_true_full_dict = []\n",
    "    hypervol_afterjump_dict = []\n",
    "\n",
    "    for i in range(0, int(max_fun_evals), nfe_interval):\n",
    "        #print('iter = ' + str(i))\n",
    "    \n",
    "        current_pareto_front = pf_dict[i]\n",
    "        current_true_pareto_front = pf_true_dict[i]\n",
    "        #current_feas_scores = pf_feas_dict[i]\n",
    "        #current_stab_scores = pf_stab_dict[i]\n",
    "        #current_designs = pf_designs_dict[i]\n",
    "        #print('current_pareto_front')\n",
    "        #print(current_pareto_front)\n",
    "        #print('current_true_pareto_front')\n",
    "        #print(current_true_pareto_front)\n",
    "        #print('\\n')\n",
    "        current_pf_normalized = []\n",
    "        current_pf_normalized_afterjump = []\n",
    "        current_pf_true_normalized = []\n",
    "        for pareto_design in current_pareto_front:\n",
    "            obj1_normalized = (pareto_design[0] - obj_norm_min_full[0])/(obj_norm_max_full[0] - obj_norm_min_full[0])\n",
    "            obj2_normalized = (pareto_design[1] - obj_norm_min_full[1])/(obj_norm_max_full[1] - obj_norm_min_full[1])\n",
    "            current_pf_normalized.append([obj1_normalized, obj2_normalized])\n",
    "            if ((i >= nfe_jump) and nfe_jump_achieved):\n",
    "                obj1_normalized_afterjump = (pareto_design[0] - obj_norm_min_afterjump[0])/(obj_norm_max_afterjump[0] - obj_norm_min_afterjump[0])\n",
    "                obj2_normalized_afterjump = (pareto_design[1] - obj_norm_min_afterjump[1])/(obj_norm_max_afterjump[1] - obj_norm_min_afterjump[1])\n",
    "                current_pf_normalized_afterjump.append([obj1_normalized_afterjump, obj2_normalized_afterjump])\n",
    "            \n",
    "        for pareto_design_true in current_true_pareto_front:\n",
    "            obj1_true_normalized = (pareto_design_true[0] - obj_norm_true_min_full[0])/(obj_norm_true_max_full[0] - obj_norm_true_min_full[0])\n",
    "            obj2_true_normalized = (obj_norm_true_max_full[1] - pareto_design_true[1])/(obj_norm_true_max_full[1] - obj_norm_true_min_full[1])\n",
    "            current_pf_true_normalized.append([obj1_true_normalized, obj2_true_normalized])\n",
    "            \n",
    "        #print('current_pf_normalized')\n",
    "        #print(current_pf_normalized)\n",
    "        current_hv = compute_hv(current_pf_normalized)\n",
    "        hypervol_full_dict.append([i, current_hv])\n",
    "        if ((i >= nfe_jump) and nfe_jump_achieved):\n",
    "            #print('current_pf_normalized_afterjump')\n",
    "            #print(current_pf_normalized_afterjump)\n",
    "            current_hv_afterjump = compute_hv(current_pf_normalized_afterjump)\n",
    "            hypervol_afterjump_dict.append([i, current_hv_afterjump])\n",
    "        \n",
    "        #print('current_pf_true_normalized')\n",
    "        #print(current_pf_true_normalized)\n",
    "        current_hv_true = compute_hv(current_pf_true_normalized)\n",
    "        hypervol_true_full_dict.append([i, current_hv_true])\n",
    "        \n",
    "    return hypervol_full_dict, hypervol_true_full_dict, hypervol_afterjump_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute and store hypervolume plots for all runs\n",
    "def store_hypervolumes_allruns(fibre_stif, algorit, bias_init, n_runs):\n",
    "    hv_full_dict_allruns = {new_list: [] for new_list in range(n_runs)}\n",
    "    hv_afterjump_dict_allruns = {new_list: [] for new_list in range(n_runs)}\n",
    "    hv_true_dict_allruns = {new_list: [] for new_list in range(n_runs)}\n",
    "    \n",
    "    nfe_jump_allruns = np.zeros(n_runs)\n",
    "    obj1_max_full_allruns = np.zeros(n_runs)\n",
    "    obj1_min_full_allruns = np.zeros(n_runs)\n",
    "    obj2_max_full_allruns = np.zeros(n_runs)\n",
    "    obj2_min_full_allruns = np.zeros(n_runs)\n",
    "    obj1_max_aj_allruns = np.zeros(n_runs)\n",
    "    obj1_min_aj_allruns = np.zeros(n_runs)\n",
    "    obj2_max_aj_allruns = np.zeros(n_runs)\n",
    "    obj2_min_aj_allruns = np.zeros(n_runs)\n",
    "    obj1_max_true_allruns = np.zeros(n_runs)\n",
    "    obj1_min_true_allruns = np.zeros(n_runs)\n",
    "    obj2_max_true_allruns = np.zeros(n_runs)\n",
    "    obj2_min_true_allruns = np.zeros(n_runs)\n",
    "    \n",
    "    pf_arrays_dict = {new_list: [] for new_list in range(n_runs)}\n",
    "    pf_true_arrays_dict = {new_list: [] for new_list in range(n_runs)}\n",
    "    max_f_evals_array = np.zeros(n_runs)\n",
    "    nfe_jump_recorded_array = []\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        print('Computing pareto fronts for run ' + str(i))\n",
    "        pf_arr_i, pf_true_arr_i, obj_norm_full_i, obj_norm_aj_i, obj_norm_true_i, jump_nfe_i, max_f_evals_i, nfe_jump_recorded_i = extract_data_from_csv(fibre_stif, algorit, bias_init, i) \n",
    "        pf_arrays_dict[i] = pf_arr_i\n",
    "        pf_true_arrays_dict[i] = pf_true_arr_i\n",
    "        nfe_jump_allruns[i] = jump_nfe_i\n",
    "        max_f_evals_array[i] = max_f_evals_i\n",
    "        nfe_jump_recorded_array.append(nfe_jump_recorded_i)\n",
    "        \n",
    "        obj1_norm_max_full_i = obj_norm_full_i[1][0]\n",
    "        obj2_norm_max_full_i = obj_norm_full_i[1][1]\n",
    "        obj1_norm_min_full_i = obj_norm_full_i[0][0]\n",
    "        obj2_norm_min_full_i = obj_norm_full_i[0][1]\n",
    "        obj1_max_full_allruns[i] = obj1_norm_max_full_i\n",
    "        obj2_max_full_allruns[i] = obj2_norm_max_full_i\n",
    "        obj1_min_full_allruns[i] = obj1_norm_min_full_i\n",
    "        obj2_min_full_allruns[i] = obj2_norm_min_full_i\n",
    "            \n",
    "        obj1_norm_max_aj_i = obj_norm_aj_i[1][0]\n",
    "        obj2_norm_max_aj_i = obj_norm_aj_i[1][1]\n",
    "        obj1_norm_min_aj_i = obj_norm_aj_i[0][0]\n",
    "        obj2_norm_min_aj_i = obj_norm_aj_i[0][1]\n",
    "        obj1_max_aj_allruns[i] = obj1_norm_max_aj_i\n",
    "        obj2_max_aj_allruns[i] = obj2_norm_max_aj_i\n",
    "        obj1_min_aj_allruns[i] = obj1_norm_min_aj_i\n",
    "        obj2_min_aj_allruns[i] = obj2_norm_min_aj_i\n",
    "        \n",
    "        obj1_norm_max_true_i = obj_norm_true_i[1][0]\n",
    "        obj2_norm_max_true_i = obj_norm_true_i[1][1]\n",
    "        obj1_norm_min_true_i = obj_norm_true_i[0][0]\n",
    "        obj2_norm_min_true_i = obj_norm_true_i[0][1]\n",
    "        obj1_max_true_allruns[i] = obj1_norm_max_true_i\n",
    "        obj2_max_true_allruns[i] = obj2_norm_max_true_i\n",
    "        obj1_min_true_allruns[i] = obj1_norm_min_true_i\n",
    "        obj2_min_true_allruns[i] = obj2_norm_min_true_i\n",
    "    \n",
    "    obj1_min_full_overall = np.min(obj1_min_full_allruns)\n",
    "    obj2_min_full_overall = np.min(obj2_min_full_allruns)\n",
    "    obj1_max_full_overall = np.max(obj1_max_full_allruns)\n",
    "    obj2_max_full_overall = np.max(obj2_max_full_allruns)\n",
    "    \n",
    "    obj1_min_aj_overall = np.min(obj1_min_aj_allruns)\n",
    "    obj2_min_aj_overall = np.min(obj2_min_aj_allruns)\n",
    "    obj1_max_aj_overall = np.max(obj1_max_aj_allruns)\n",
    "    obj2_max_aj_overall = np.max(obj2_max_aj_allruns)\n",
    "    \n",
    "    obj1_min_true_overall = np.min(obj1_min_true_allruns)\n",
    "    obj2_min_true_overall = np.min(obj2_min_true_allruns)\n",
    "    obj1_max_true_overall = np.max(obj1_max_true_allruns)\n",
    "    obj2_max_true_overall = np.max(obj2_max_true_allruns)\n",
    "            \n",
    "    obj_norm_full_allruns = [[obj1_min_full_overall, obj2_min_full_overall], [obj1_max_full_overall, obj2_max_full_overall]]\n",
    "    obj_norm_aj_allruns = [[obj1_min_aj_overall, obj2_min_aj_overall], [obj1_max_aj_overall, obj2_max_aj_overall]]\n",
    "    obj_norm_true_allruns = [[obj1_min_true_overall, obj2_min_true_overall], [obj1_max_true_overall, obj2_max_true_overall]]    \n",
    "    \n",
    "    #print('obj_norm_full_allruns')\n",
    "    #print(obj_norm_full_allruns)\n",
    "    #print('obj_norm_aj_allruns')\n",
    "    #print(obj_norm_aj_allruns)\n",
    "    #print('obj_norm_true_allruns')\n",
    "    #print(obj_norm_true_allruns)\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        print('Reading and computing hypervolumes for run ' + str(i))\n",
    "        current_pf_arr = pf_arrays_dict[i]\n",
    "        current_pf_arr_true = pf_true_arrays_dict[i]\n",
    "        hv_full_dict, hv_true_dict, hv_aj_dict = compute_hv_arrays_from_csv_data(current_pf_arr, current_pf_arr_true, obj_norm_full_allruns, obj_norm_aj_allruns, obj_norm_true_allruns, nfe_jump_allruns[i], max_f_evals_array[i], nfe_jump_recorded_array[i])\n",
    "        #print('RUN No.' + str(i))\n",
    "        #print('length of hv_full_dict')\n",
    "        #print(len(hv_full_dict))\n",
    "        #print('length of hv_aj_dict')\n",
    "        #print(len(hv_aj_dict))\n",
    "        #print('length of hv_true_dict')\n",
    "        #print(len(hv_true_dict))\n",
    "        hv_full_dict_allruns[i] = hv_full_dict\n",
    "        hv_afterjump_dict_allruns[i] = hv_aj_dict\n",
    "        hv_true_dict_allruns[i] = hv_true_dict\n",
    "        \n",
    "    ## Compute the mean and standard deviation of hypervolume values\n",
    "    hv_full_dict_run0 = hv_full_dict_allruns[0]\n",
    "    nfe_array_full_run0 = [hv_array[0] for hv_array in hv_full_dict_run0]\n",
    "    n_datapoints = len(nfe_array_full_run0)\n",
    "    hypervol_vals = np.zeros(n_runs)\n",
    "    hypervol_median_full = np.zeros(n_datapoints)\n",
    "    hypervol_1q_full = np.zeros(n_datapoints)\n",
    "    hypervol_3q_full = np.zeros(n_datapoints)\n",
    "    for i in range(n_datapoints):\n",
    "        for j in range(n_runs):\n",
    "            hv_full_dict_j = hv_full_dict_allruns[j]\n",
    "            hv_current_array = [hv_array[1] for hv_array in hv_full_dict_j]\n",
    "            hypervol_vals[j] = hv_current_array[i]\n",
    "        hypervol_median_full[i] = statistics.median(hypervol_vals)\n",
    "        hypervol_1q_full[i] = np.percentile(hypervol_vals, 25)\n",
    "        hypervol_3q_full[i] = np.percentile(hypervol_vals, 75)\n",
    "        \n",
    "    hv_stats_full = [hypervol_median_full, hypervol_1q_full, hypervol_3q_full]\n",
    "        \n",
    "    hv_true_dict_run0 = hv_true_dict_allruns[0]\n",
    "    nfe_array_true_run0 = [hv_array[0] for hv_array in hv_true_dict_run0]\n",
    "    n_datapoints = len(nfe_array_true_run0)\n",
    "    hypervol_vals = np.zeros(n_runs)\n",
    "    #print('Number of datapoints')\n",
    "    #print(n_datapoints)\n",
    "    hypervol_median_true = np.zeros(n_datapoints)\n",
    "    hypervol_1q_true = np.zeros(n_datapoints)\n",
    "    hypervol_3q_true = np.zeros(n_datapoints)\n",
    "    for i in range(n_datapoints):\n",
    "        for j in range(n_runs):\n",
    "            hv_true_dict_j = hv_true_dict_allruns[j]\n",
    "            hv_current_array = [hv_array[1] for hv_array in hv_true_dict_j]\n",
    "            #print('Number of elements in true hv array of run ' + str(j))\n",
    "            #print(len(hv_current_array))\n",
    "            hypervol_vals[j] = hv_current_array[i]\n",
    "        hypervol_median_true[i] = statistics.median(hypervol_vals)\n",
    "        hypervol_1q_true[i] = np.percentile(hypervol_vals, 25)\n",
    "        hypervol_3q_true[i] = np.percentile(hypervol_vals, 75)\n",
    "        \n",
    "    hv_stats_true = [hypervol_median_true, hypervol_1q_true, hypervol_3q_true]\n",
    "    \n",
    "    ###### Median, 1q and 3q computation for afterjump hv values to be written ######\n",
    "    \n",
    "    return hv_full_dict_allruns, hv_afterjump_dict_allruns, hv_true_dict_allruns, hv_stats_full, hv_stats_true, nfe_jump_allruns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hypervolume_allruns(hv_dict, hv_stats, n_runs, savefig_name):\n",
    "    ## Plotting\n",
    "    print('Plotting')\n",
    "    fig1 = plt.figure(1)\n",
    "    for i in range(n_runs):\n",
    "        hv_dict_i = hv_dict[i]\n",
    "        nfe_array_i = [hv_array[0] for hv_array in hv_dict_i]\n",
    "        hv_array_i = [hv_array[1] for hv_array in hv_dict_i]\n",
    "        plt.plot(nfe_array_i,hv_array_i)\n",
    "    plt.xlabel('Number of Function Evaluations')\n",
    "    plt.ylabel('Hypervolume')\n",
    "    plt.title('Hypervolume vs NFE for each run')\n",
    "    plt.show()\n",
    "    #fig1.savefig('HV_plot_allruns_' + savefig_name + '.png')\n",
    "\n",
    "    hv_dict_0 = hv_dict[0]\n",
    "    nfe_array_0 = [hv_array[0] for hv_array in hv_dict_0]\n",
    "    hv_median = hv_stats[0]\n",
    "    hv_1q = hv_stats[1]\n",
    "    hv_3q = hv_stats[2]\n",
    "    fig2 = plt.figure(1)\n",
    "    plt.plot(nfe_array_0,hv_median, 'b-', label='Median')\n",
    "    plt.plot(nfe_array_0,hv_1q, 'r-', label='1st Quartile')\n",
    "    plt.plot(nfe_array_0,hv_3q, 'g-', label='3rd Quartile')\n",
    "    plt.xlabel('Number of Function Evaluations')\n",
    "    plt.ylabel('Hypervolume')\n",
    "    plt.title('Averaged Hypervolume vs NFE')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    #fig2.savefig('HV_plot_averaged_' + savefig_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Program Operation\n",
    "\n",
    "# set to: true - to read results for fibre stiffness model run\n",
    "#         false - to read results for truss model run\n",
    "model_fib = True\n",
    "\n",
    "# set algorithm_choie to: eps_moea - if Epsilon MOEA was used\n",
    "#                         aos_feas_stab_false - if AOS MOEA was used\n",
    "#                         sc_dnf - if Disjunctive Normal Form was used\n",
    "#                         sc_ach - if Adaptive Constraint Handling was used\n",
    "\n",
    "# set to: true - if biased initialization is used\n",
    "#         false - if random initialization is used\n",
    "biased_initialization = True\n",
    "\n",
    "number_runs = 30\n",
    "\n",
    "# Name for saving plots\n",
    "# mode: 0 - full\n",
    "#       1 - true\n",
    "#       2 - afterjump\n",
    "def determine_savename(fibre_model, algor, init_biased, mode):\n",
    "    if fibre_model:\n",
    "        savename1 = 'fib_'\n",
    "    else:\n",
    "        savename1 = 'truss_'\n",
    "        \n",
    "    if algor == 'eps_moea':\n",
    "        savename2 = 'eps_'\n",
    "    elif algor == 'aos_feas_stab_false':\n",
    "        savename2 = 'aos_'\n",
    "    elif algor == 'sc_dnf':\n",
    "        savename2 = 'dnf_'\n",
    "    elif algor == 'sc_ach':\n",
    "        savename2 = 'ach_'\n",
    "        \n",
    "    if init_biased:\n",
    "        savename3 = 'biasedinit_'\n",
    "    else:\n",
    "        savename3 = 'randominit_'\n",
    "        \n",
    "    if mode == 0:\n",
    "        savename4 = 'full_'\n",
    "    elif mode == 1:\n",
    "        savename4 = 'true_'\n",
    "    elif mode == 2:\n",
    "        savename4 = 'afterjump_'\n",
    "        \n",
    "    return savename1+savename2+savename3+savename4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Epsilon MOEA runs using fibre stiffness model (random initialization)\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Epsilon MOEA runs using fibre stiffness model and random initialization')\n",
    "hv_full_dict_eps_fib_rand, hv_aj_dict_eps_fib_rand, hv_true_dict_eps_fib_rand, hv_stats_full_eps_fib_rand, hv_stats_true_eps_fib_rand, nfe_jump_eps_fib_rand = store_hypervolumes_allruns(model_fib, 'eps_moea', not biased_initialization, number_runs)\n",
    "#print('hv_true_dict_eps_fib_rand')\n",
    "#print(hv_true_dict_eps_fib_rand)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_eps_fib_rand = determine_savename(model_fib, 'eps_moea', not biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_eps_fib_rand, hv_stats_full_eps_fib_rand, number_runs, savename_full_eps_fib_rand)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_eps_fib_rand = determine_savename(model_fib, 'eps_moea', not biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_eps_fib_rand, hv_stats_true_eps_fib_rand, number_runs, savename_true_eps_fib_rand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Epsilon MOEA runs using truss stiffness model (random initialization)\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Epsilon MOEA runs using truss model and random initialization')\n",
    "hv_full_dict_eps_truss_rand, hv_aj_dict_eps_truss_rand, hv_true_dict_eps_truss_rand, hv_stats_full_eps_truss_rand, hv_stats_true_eps_truss_rand, nfe_jump_eps_truss_rand = store_hypervolumes_allruns(not model_fib, 'eps_moea', not biased_initialization, number_runs)\n",
    "#print('hv_true_dict_eps_fib_bias')\n",
    "#print(hv_true_dict_eps_fib_bias)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_eps_truss_rand = determine_savename(not model_fib, 'eps_moea', not biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_eps_truss_rand, hv_stats_full_eps_truss_rand, number_runs, savename_full_eps_truss_rand)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_eps_truss_rand = determine_savename(not model_fib, 'eps_moea', not biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_eps_truss_rand, hv_stats_true_eps_truss_rand, number_runs, savename_true_eps_truss_rand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Epsilon MOEA runs using fibre stiffness model (biased initialization)\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Epsilon MOEA runs using fibre stiffness model and biased initialization')\n",
    "hv_full_dict_eps_fib_bias, hv_aj_dict_eps_fib_bias, hv_true_dict_eps_fib_bias, hv_stats_full_eps_fib_bias, hv_stats_true_eps_fib_bias, nfe_jump_eps_fib_bias = store_hypervolumes_allruns(model_fib, 'eps_moea', biased_initialization, number_runs)\n",
    "#print('hv_true_dict_eps_fib_bias')\n",
    "#print(hv_true_dict_eps_fib_bias)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_eps_fib_bias = determine_savename(model_fib, 'eps_moea', biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_eps_fib_bias, hv_stats_full_eps_fib_bias, number_runs, savename_full_eps_fib_bias)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_eps_fib_bias = determine_savename(model_fib, 'eps_moea', biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_eps_fib_bias, hv_stats_true_eps_fib_bias, number_runs, savename_true_eps_fib_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Epsilon MOEA runs using truss stiffness model (biased initialization) (NaN values in some runs)\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Epsilon MOEA runs using truss model and biased initialization')\n",
    "hv_full_dict_eps_truss_bias, hv_aj_dict_eps_truss_bias, hv_true_dict_eps_truss_bias, hv_stats_full_eps_truss_bias, hv_stats_true_eps_truss_bias, nfe_jump_eps_truss_bias = store_hypervolumes_allruns(not model_fib, 'eps_moea', biased_initialization, number_runs)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_eps_truss_bias = determine_savename(not model_fib, 'eps_moea', biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_eps_truss_bias, hv_stats_full_eps_truss_bias, number_runs, savename_full_eps_truss_bias)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_eps_truss_bias = determine_savename(not model_fib, 'eps_moea', biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_eps_truss_bias, hv_stats_true_eps_truss_bias, number_runs, savename_true_eps_truss_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AOS MOEA runs using fibre stiffness model \n",
    "print('Hypervolume computation for ' + str(number_runs) + ' AOS MOEA runs using fibre stiffness model')\n",
    "hv_full_dict_aos_fib, hv_aj_dict_aos_fib, hv_true_dict_aos_fib, hv_stats_full_aos_fib, hv_stats_true_aos_fib, nfe_jump_aos_fib = store_hypervolumes_allruns(model_fib, 'aos_feas_stab_false', not biased_initialization, number_runs)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_aos_fib = determine_savename(model_fib, 'aos_feas_stab_false', not biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_aos_fib, hv_stats_full_aos_fib, number_runs, savename_full_aos_fib)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_aos_fib = determine_savename(model_fib, 'aos_feas_stab_false', not biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_aos_fib, hv_stats_true_aos_fib, number_runs, savename_true_aos_fib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AOS MOEA runs using truss model \n",
    "print('Hypervolume computation for ' + str(number_runs) + ' AOS MOEA runs using truss model')\n",
    "hv_full_dict_aos_truss, hv_aj_dict_aos_truss, hv_true_dict_aos_truss, hv_stats_full_aos_truss, hv_stats_true_aos_truss, nfe_jump_aos_truss = store_hypervolumes_allruns(not model_fib, 'aos_feas_stab_false', not biased_initialization, number_runs)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_aos_truss = determine_savename(not model_fib, 'aos_feas_stab_false', not biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_aos_truss, hv_stats_full_aos_truss, number_runs, savename_full_aos_truss)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_aos_truss = determine_savename(not model_fib, 'aos_feas_stab_false', not biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_aos_truss, hv_stats_true_aos_truss, number_runs, savename_true_aos_truss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Disjunctive Normal Form runs using fibre stiffness model\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Disjunctive Normal Form runs using fibre stiffness model')\n",
    "hv_full_dict_dnf_fib, hv_aj_dict_dnf_fib, hv_true_dict_dnf_fib, hv_stats_full_dnf_fib, hv_stats_true_dnf_fib, nfe_jump_dnf_fib = store_hypervolumes_allruns(model_fib, 'sc_dnf', not biased_initialization, number_runs)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_dnf_fib = determine_savename(model_fib, 'sc_dnf', biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_dnf_fib, hv_stats_full_dnf_fib, number_runs, savename_full_dnf_fib)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_dnf_fib = determine_savename(model_fib, 'sc_dnf', biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_dnf_fib, hv_stats_true_dnf_fib, number_runs, savename_true_dnf_fib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Disjunctive Normal Form runs using truss model\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Disjunctive Normal Form runs using truss model')\n",
    "hv_full_dict_dnf_truss, hv_aj_dict_dnf_truss, hv_true_dict_dnf_truss, hv_stats_full_dnf_truss, hv_stats_true_dnf_truss, nfe_jump_dnf_truss = store_hypervolumes_allruns(not model_fib, 'sc_dnf', not biased_initialization, number_runs)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_dnf_truss = determine_savename(not model_fib, 'sc_dnf', biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_dnf_truss, hv_stats_full_dnf_truss, number_runs, savename_full_dnf_truss)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_dnf_truss = determine_savename(not model_fib, 'sc_dnf', biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_dnf_truss, hv_stats_true_dnf_truss, number_runs, savename_true_dnf_truss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Adaptive Constraint Handling runs using fibre stiffness model\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Adaptive Constraint Handling runs using fibre stiffness model')\n",
    "hv_full_dict_ach_fib, hv_aj_dict_ach_fib, hv_true_dict_ach_fib, hv_stats_full_ach_fib, hv_stats_true_ach_fib, nfe_jump_ach_fib = store_hypervolumes_allruns(model_fib, 'sc_ach', not biased_initialization, number_runs)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_ach_fib = determine_savename(model_fib, 'sc_ach', biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_ach_fib, hv_stats_full_ach_fib, number_runs, savename_full_ach_fib)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_ach_fib = determine_savename(model_fib, 'sc_ach', biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_ach_fib, hv_stats_true_ach_fib, number_runs, savename_true_ach_fib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Adaptive Constraint Handling runs using truss model\n",
    "print('Hypervolume computation for ' + str(number_runs) + ' Adaptive Constraint Handling runs using truss model')\n",
    "hv_full_dict_ach_truss, hv_aj_dict_ach_truss, hv_true_dict_ach_truss, hv_stats_full_ach_truss, hv_stats_true_ach_truss, nfe_jump_ach_truss = store_hypervolumes_allruns(not model_fib, 'sc_ach', not biased_initialization, number_runs)\n",
    "print('Plotting hypervolume for full penalized objectives case')\n",
    "savename_full_ach_truss = determine_savename(not model_fib, 'sc_ach', biased_initialization, 0)\n",
    "plot_hypervolume_allruns(hv_full_dict_ach_truss, hv_stats_full_ach_truss, number_runs, savename_full_ach_truss)\n",
    "print('Plotting hypervolume for true objectives case')\n",
    "savename_true_ach_truss = determine_savename(not model_fib, 'sc_ach', biased_initialization, 1)\n",
    "plot_hypervolume_allruns(hv_true_dict_ach_truss, hv_stats_true_ach_truss, number_runs, savename_true_ach_truss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### BOX PLOTS FOR NFE TO OVERCOME FEASIBILITY BARRIER\n",
    "\n",
    "fig3 = plt.figure(1)\n",
    "ax = fig3.add_axes([0,0,1,1])\n",
    "bp = ax.boxplot([nfe_jump_eps_fib_rand,nfe_jump_eps_truss_rand,nfe_jump_eps_fib_bias,nfe_jump_eps_truss_bias,nfe_jump_aos_fib,nfe_jump_aos_truss,nfe_jump_dnf_fib,nfe_jump_dnf_truss,nfe_jump_ach_fib,nfe_jump_ach_truss])\n",
    "ax.set_xticklabels(['fib_eps_rand','truss_eps_rand','fib_eps_bias','truss_eps_bias','fib_aos','truss_aos','dnf_fib','dnf_truss','ach_fib','ach_truss'])\n",
    "plt.ylabel('Number of Function Evaluations')\n",
    "plt.title('Boxplot for NFE to clear feasibility threshold')\n",
    "#fig3.savefig('NFE_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

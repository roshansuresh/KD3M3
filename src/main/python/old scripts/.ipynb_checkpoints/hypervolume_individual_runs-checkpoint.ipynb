{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygmo import hypervolume\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Modified from Pau's code\n",
    "def compute_pareto_front(population):\n",
    "    #print(np.shape(np.array(population)))\n",
    "    #print(population)\n",
    "    pop_size = len(population)\n",
    "    obj_num = 2\n",
    "\n",
    "    domination_counter = [0] * pop_size\n",
    "\n",
    "    for i in range(pop_size):\n",
    "        for j in range(i+1, pop_size):\n",
    "            # check each objective for dominance\n",
    "            dominate = [0] * obj_num\n",
    "            for k in range(obj_num):\n",
    "                if population[i][k] > population[j][k]:\n",
    "                    dominate[k] = 1\n",
    "                elif population[i][k] < population[j][k]:\n",
    "                    dominate[k] = -1\n",
    "            if -1 not in dominate and 1 in dominate:\n",
    "                domination_counter[i] += 1\n",
    "            elif -1 in dominate and 1 not in dominate:\n",
    "                domination_counter[j] += 1\n",
    "\n",
    "    pareto_solutions = []\n",
    "    for i in range(len(domination_counter)):\n",
    "        if domination_counter[i] == 0:\n",
    "            pareto_solutions.append(population[i])\n",
    "    return pareto_solutions\n",
    "\n",
    "def compute_hv(population):\n",
    "    array_archs = np.zeros((len(population), 2))\n",
    "    for i in range(len(population)):\n",
    "        array_archs[i] = population[i]\n",
    "    hv_object = hypervolume(array_archs)\n",
    "    hv = hv_object.compute([1.1,1.1])/1.1**2\n",
    "    return hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read data from the appropriate csv file\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# set to: true - to read results for fibre stiffness model run\n",
    "#         false - to read results for truss model run\n",
    "fibre_stiffness = True\n",
    "\n",
    "# set to: true - if Epsilon MOEA was used\n",
    "#         false - if AOS MOEA was used\n",
    "eps_moea = True\n",
    "\n",
    "# set to: true - if biased initialization is used\n",
    "#         false - if random initialization is used\n",
    "biased_init = True\n",
    "\n",
    "run_number = 1 # starts from 0\n",
    "\n",
    "filepath = 'C:\\\\SEAK Lab\\\\SEAK Lab Github\\\\KD3M3\\\\Truss_AOS\\\\result\\\\'\n",
    "if eps_moea:\n",
    "    fileloc = 'Epsilon MOEA Runs\\\\'\n",
    "    if fibre_stiffness:\n",
    "        filename_model = 'Fibre Stiffness code run results\\\\'\n",
    "        if biased_init:\n",
    "            filename = 'Biased Initialization\\\\EpsilonMOEA_emoea' + str(run_number) + '_biasedinit_fibrestiffness_fullpop.csv'\n",
    "        else:\n",
    "            filename = 'Random Initialization\\\\EpsilonMOEA_emoea' + str(run_number) + '_fibrestiffness_fullpop.csv'\n",
    "    else: \n",
    "        filename_model = 'Truss code run results\\\\'\n",
    "        if biased_init:\n",
    "            filename = 'Biased Initialization\\\\EpsilonMOEA_emoea' + str(run_number) + '_biasedinit_trussstiffness_fullpop.csv'\n",
    "        else:\n",
    "            filename = 'Random Initialization\\\\EpsilonMOEA_emoea' + str(run_number) + '_trussstiffness_fullpop.csv'            \n",
    "else:\n",
    "    fileloc = 'AOS MOEA Runs\\\\'\n",
    "    if fibre_stiffness:\n",
    "        filename = 'Feas and Stab False\\\\Fibre Stiffness code run results\\\\AOSMOEA_constraint_adaptive' + str(run_number) + '_fibrestiffness_fullpop.csv'\n",
    "    else: \n",
    "        filename = 'Feas and Stab False\\\\Truss code run results\\\\AOSMOEA_constraint_adaptive' + str(run_number) + '_trussstiffness_fullpop.csv' \n",
    "    filename = ''\n",
    "\n",
    "full_filepath = filepath + fileloc + filename_model + filename\n",
    "\n",
    "with open(full_filepath,newline='') as csvfile:\n",
    "    data = [row for row in csv.reader(csvfile)]\n",
    "    designs = [\"\" for x in range(len(data)-1)]\n",
    "    num_func_evals = np.zeros(len(data)-1)\n",
    "    pen_obj1 = np.zeros(len(data)-1)\n",
    "    pen_obj2 = np.zeros(len(data)-1)\n",
    "    feas_scores = np.zeros(len(data)-1)\n",
    "    stab_scores = np.zeros(len(data)-1)\n",
    "    for x in range(len(data)-1):\n",
    "        designs[x] = data[x+1][0]\n",
    "        num_func_evals[x] = int(data[x+1][1])\n",
    "        pen_obj1[x] = float(data[x+1][2])\n",
    "        pen_obj2[x] = float(data[x+1][3])\n",
    "        feas_scores[x] = float(data[x+1][4])\n",
    "        stab_scores[x] = float(data[x+1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Useful functions\n",
    "def compute_true_objectives(pen_obj1, pen_obj2, feas_score, stab_score, fib_stiff):\n",
    "    pen_fac = 1\n",
    "    if fib_stiff:\n",
    "        pen_fac = 1.5\n",
    "    pen = (np.log10(np.absolute(feas_score)) + np.log10(np.absolute(stab_score)))/2\n",
    "    obj1 = 15*(pen_obj1 + pen_fac*pen)\n",
    "    obj2 = -8500*(pen_obj2 + pen_fac*pen)\n",
    "    return obj1, obj2\n",
    "\n",
    "def get_feasibility_score(feas_array, index):\n",
    "    return feas_array[index]\n",
    "\n",
    "def get_stability_score(stab_array, index):\n",
    "    return stab_array[index]\n",
    "\n",
    "def get_design(design_array, index):\n",
    "    return design_array[index]\n",
    "\n",
    "def find_last_index(val,search_list):\n",
    "    return len(search_list) - search_list[::-1].index(val) - 1\n",
    "\n",
    "def find_closest_index(val,search_list):\n",
    "    val_diff = np.array(search_list) - val\n",
    "    closest_index = np.argmin(np.abs(val_diff))\n",
    "    return closest_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sort num_fun_evals (and obj1 & obj2, feas and stab scores) in ascending order\n",
    "n_func_evals = num_func_evals\n",
    "sort_indices = np.argsort(n_func_evals)\n",
    "pen_obj1_sorted = list(pen_obj1[sort_indices])\n",
    "pen_obj2_sorted = list(pen_obj2[sort_indices])\n",
    "feas_scores_sorted = list(feas_scores[sort_indices])\n",
    "stab_scores_sorted = list(stab_scores[sort_indices])\n",
    "true_obj1_sorted = np.zeros(len(pen_obj1))\n",
    "true_obj2_sorted = np.zeros(len(pen_obj2))\n",
    "\n",
    "for i in range(len(pen_obj1_sorted)):\n",
    "    obj1_true, obj2_true = compute_true_objectives(pen_obj1_sorted[i], pen_obj2_sorted[i], feas_scores_sorted[i], stab_scores_sorted[i], fibre_stiffness)\n",
    "    true_obj1_sorted[i] = obj1_true\n",
    "    true_obj2_sorted[i] = obj2_true\n",
    "\n",
    "designs_sorted = []\n",
    "for i in range(len(sort_indices)):\n",
    "    designs_sorted.append(designs[sort_indices[i]])\n",
    "    \n",
    "nfe_list_sorted = list(n_func_evals[sort_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Determine normalizing objective scores for true and penalized objectives \n",
    "max_func_evals = nfe_list_sorted[-1]\n",
    "\n",
    "obj_normalize_max_fullrun = [np.max(pen_obj1_sorted), np.max(pen_obj2_sorted)]\n",
    "obj_normalize_min_fullrun = [np.min(pen_obj1_sorted), np.min(pen_obj2_sorted)]\n",
    "\n",
    "obj_true_normalize_max_fullrun = [np.max(true_obj1_sorted), np.max(true_obj2_sorted)]\n",
    "obj_true_normalize_min_fullrun = [np.min(true_obj1_sorted), np.min(true_obj2_sorted)]\n",
    "\n",
    "obj1_normalize_max_afterjump = 0\n",
    "obj1_normalize_min_afterjump = 0\n",
    "obj2_normalize_max_afterjump = 0\n",
    "obj2_normalize_min_afterjump = 0\n",
    "\n",
    "pareto_front_dict = {}\n",
    "pareto_front_feas_dict = {}\n",
    "pareto_front_stab_dict = {}\n",
    "pareto_front_designs_dict = {}\n",
    "pareto_front_true_dict = {}\n",
    "count = 0\n",
    "pop_size = int(find_last_index(0, nfe_list_sorted))\n",
    "nfe_interval = 50\n",
    "nfe_jump_recorded = False\n",
    "jump_nfe = 0\n",
    "\n",
    "for i in range(0, int(max_func_evals), nfe_interval):\n",
    "    #print('iter = ' + str(i))\n",
    "    \n",
    "    if (i < 100):\n",
    "        nfe_index_current = pop_size\n",
    "    else:\n",
    "        nfe_index_current = find_closest_index(i, nfe_list_sorted)\n",
    "        \n",
    "    nfe_array_current = nfe_list_sorted[:nfe_index_current]\n",
    "    current_population = []\n",
    "    for j in range(len(nfe_array_current)):\n",
    "        current_population.append([pen_obj1_sorted[j], pen_obj2_sorted[j]])\n",
    "\n",
    "    current_pareto_front_all = compute_pareto_front(current_population)\n",
    "    #current_pareto_front = list(set(current_pareto_front_all))\n",
    "    current_pareto_front = np.unique(current_pareto_front_all, axis=0)\n",
    "    \n",
    "    current_pareto_feas_scores = []\n",
    "    current_pareto_stab_scores = []\n",
    "    current_pareto_designs = []\n",
    "    current_pareto_true_obj = []\n",
    "    for pareto_design in current_pareto_front:\n",
    "        design_index = pen_obj1_sorted.index(pareto_design[0])\n",
    "        design_feas_score = get_feasibility_score(feas_scores_sorted, design_index)\n",
    "        design_stab_score = get_stability_score(stab_scores_sorted, design_index)\n",
    "        current_pareto_feas_scores.append(design_feas_score)\n",
    "        current_pareto_stab_scores.append(design_stab_score)\n",
    "        current_pareto_designs.append(get_design(designs_sorted, design_index))\n",
    "        true_obj1, true_obj2 = compute_true_objectives(pareto_design[0], pareto_design[1], design_feas_score, design_stab_score, fibre_stiffness)\n",
    "        current_pareto_true_obj.append([true_obj1, true_obj2])\n",
    "        \n",
    "    pareto_front_dict[i] = current_pareto_front\n",
    "    pareto_front_feas_dict[i] = current_pareto_feas_scores\n",
    "    pareto_front_stab_dict[i] = current_pareto_stab_scores\n",
    "    pareto_front_designs_dict[i] = current_pareto_designs\n",
    "    pareto_front_true_dict[i] = current_pareto_true_obj\n",
    "    \n",
    "    nonzero_feas_scores = True in (feas_score > 0.1 for feas_score in current_pareto_feas_scores)\n",
    "    if (nonzero_feas_scores):\n",
    "        if (not nfe_jump_recorded):\n",
    "            jump_nfe = i\n",
    "            nfe_jump_recorded = True\n",
    "        \n",
    "        pareto_obj1s = [pareto_design[0] for pareto_design in current_pareto_front]\n",
    "        pareto_obj2s = [pareto_design[1] for pareto_design in current_pareto_front]\n",
    "        \n",
    "        if (np.max(pareto_obj1s) > obj1_normalize_max_afterjump):\n",
    "            obj1_normalize_max_afterjump = np.max(pareto_obj1s)\n",
    "        \n",
    "        if (np.max(pareto_obj2s) > obj2_normalize_max_afterjump):\n",
    "            obj2_normalize_max_afterjump = np.max(pareto_obj2s)\n",
    "        \n",
    "        if (np.min(pareto_obj1s) < obj1_normalize_min_afterjump):\n",
    "            obj1_normalize_min_afterjump = np.min(pareto_obj1s)\n",
    "        \n",
    "        if (np.min(pareto_obj2s) < obj2_normalize_min_afterjump):\n",
    "            obj2_normalize_min_afterjump = np.min(pareto_obj2s)\n",
    "\n",
    "obj_normalize_max_afterjump = [obj1_normalize_max_afterjump, obj2_normalize_max_afterjump]\n",
    "obj_normalize_min_afterjump = [obj1_normalize_min_afterjump, obj2_normalize_min_afterjump]\n",
    "\n",
    "print(obj_normalize_max_fullrun)\n",
    "print(obj_normalize_min_fullrun)\n",
    "print(obj_normalize_max_afterjump)\n",
    "print(obj_normalize_min_afterjump)\n",
    "print(obj_true_normalize_max_fullrun)\n",
    "print(obj_true_normalize_min_fullrun)\n",
    "print(jump_nfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normalize the pareto front objectives and compute the hypervolume\n",
    "hypervol_full_dict = []\n",
    "hypervol_true_full_dict = []\n",
    "hypervol_afterjump_dict = []\n",
    "\n",
    "for i in range(0, int(max_func_evals), nfe_interval):\n",
    "    print('iter = ' + str(i))\n",
    "    \n",
    "    current_pareto_front = pareto_front_dict[i]\n",
    "    current_true_pareto_front = pareto_front_true_dict[i]\n",
    "    current_feas_scores = pareto_front_feas_dict[i]\n",
    "    current_stab_scores = pareto_front_stab_dict[i]\n",
    "    current_designs = pareto_front_designs_dict[i]\n",
    "    current_pf_normalized = []\n",
    "    current_pf_normalized_afterjump = []\n",
    "    current_pf_true_normalized = []\n",
    "    for pareto_design in current_pareto_front:\n",
    "        obj1_normalized = (pareto_design[0] - obj_normalize_min_fullrun[0])/(obj_normalize_max_fullrun[0] - obj_normalize_min_fullrun[0])\n",
    "        obj2_normalized = (pareto_design[1] - obj_normalize_min_fullrun[1])/(obj_normalize_max_fullrun[1] - obj_normalize_min_fullrun[1])\n",
    "        current_pf_normalized.append([obj1_normalized, obj2_normalized])\n",
    "        if (i >= jump_nfe):\n",
    "            obj1_normalized_afterjump = (pareto_design[0] - obj_normalize_min_afterjump[0])/(obj_normalize_max_afterjump[0] - obj_normalize_min_afterjump[0])\n",
    "            obj2_normalized_afterjump = (pareto_design[1] - obj_normalize_min_afterjump[1])/(obj_normalize_max_afterjump[1] - obj_normalize_min_afterjump[1])\n",
    "            current_pf_normalized_afterjump.append([obj1_normalized_afterjump, obj2_normalized_afterjump])\n",
    "            \n",
    "    for pareto_design_true in current_true_pareto_front:\n",
    "        obj1_true_normalized = (pareto_design_true[0] - obj_true_normalize_min_fullrun[0])/(obj_true_normalize_max_fullrun[0] - obj_true_normalize_min_fullrun[0])\n",
    "        obj2_true_normalized = (obj_true_normalize_max_fullrun[1] - pareto_design_true[1])/(obj_true_normalize_max_fullrun[1] - obj_true_normalize_min_fullrun[1])\n",
    "        current_pf_true_normalized.append([obj1_true_normalized, obj2_true_normalized])\n",
    "        \n",
    "    print('pareto front penalized objectives (normalized)')\n",
    "    print(current_pf_normalized)\n",
    "    print('pareto front penalized objectives (normalized) after jump')\n",
    "    print(current_pf_normalized_afterjump)\n",
    "    print('pareto front true objectives (normalized)')\n",
    "    print(current_pf_true_normalized)\n",
    "    print('pareto front feasibility scores')\n",
    "    print(current_feas_scores)\n",
    "    print('pareto front stability scores')\n",
    "    print(current_stab_scores)\n",
    "    print('pareto front designs')\n",
    "    print(current_designs)\n",
    "    \n",
    "    current_hv = compute_hv(current_pf_normalized)\n",
    "    hypervol_full_dict.append([i, current_hv])\n",
    "    if (i >= jump_nfe):\n",
    "        current_hv_afterjump = compute_hv(current_pf_normalized_afterjump)\n",
    "        hypervol_afterjump_dict.append([i, current_hv_afterjump])\n",
    "        \n",
    "    current_hv_true = compute_hv(current_pf_true_normalized)\n",
    "    hypervol_true_full_dict.append([i, current_hv_true])\n",
    "    \n",
    "    print('hypervolume')\n",
    "    print(current_hv)\n",
    "    if (i >= jump_nfe):\n",
    "        print('hypervolume after jump')\n",
    "        print(current_hv_afterjump)\n",
    "    print('true objectives hypervolume')\n",
    "    print(current_hv_true)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plotting\n",
    "nfe_array_fullrun = [hv_array[0] for hv_array in hypervol_full_dict]\n",
    "hv_array_fullrun = [hv_array[1] for hv_array in hypervol_full_dict]\n",
    "nfe_array_afterjump = [hv_array[0] for hv_array in hypervol_afterjump_dict]\n",
    "hv_array_afterjump = [hv_array[1] for hv_array in hypervol_afterjump_dict]\n",
    "nfe_array_true_fullrun = [hv_array[0] for hv_array in hypervol_true_full_dict]\n",
    "hv_array_true_fullrun = [hv_array[1] for hv_array in hypervol_true_full_dict]\n",
    "\n",
    "#### Plot hypervolume vs NFE\n",
    "fig1 = plt.figure(1)\n",
    "plt.plot(nfe_array_fullrun,hv_array_fullrun)\n",
    "plt.xlabel('Number of Function Evaluations')\n",
    "plt.ylabel('Hypervolume')\n",
    "plt.title('Hypervolume vs NFE')\n",
    "plt.show()\n",
    "#fig1.savefig('HV_plot_eps_truss_' + str(run_number) + '.png')\n",
    "\n",
    "#### Plot hypervolume vs NFE after hypervolume jump\n",
    "fig2 = plt.figure(1)\n",
    "plt.plot(nfe_array_afterjump,hv_array_afterjump)\n",
    "plt.xlabel('Number of Function Evaluations')\n",
    "plt.ylabel('Hypervolume')\n",
    "plt.title('Hypervolume vs NFE after jump')\n",
    "plt.show()\n",
    "#fig2.savefig('HV_plot_post_jump_eps_truss_' + str(run_number) + '.png')\n",
    "\n",
    "#### Plot true objectves hypervolume vs NFE\n",
    "fig3 = plt.figure(1)\n",
    "plt.plot(nfe_array_true_fullrun,hv_array_true_fullrun)\n",
    "plt.xlabel('Number of Function Evaluations')\n",
    "plt.ylabel('Hypervolume')\n",
    "plt.title('True Objectives Hypervolume vs NFE')\n",
    "plt.show()\n",
    "#fig3.savefig('HV_plot_eps_truss_' + str(run_number) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

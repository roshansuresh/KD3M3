{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygmo import hypervolume\n",
    "import csv\n",
    "import statistics\n",
    "import math\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from scipy.stats import mannwhitneyu\n",
    "from functools import reduce\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Useful functions and parameter defintions \n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Create array of NFE values at which to compute hypervolume (assumes max function evaluations is 6000)\n",
    "n_iter_total = 100 # Total number of points in NFE array (1 more than input value to incorporate 0)\n",
    "n_iter_init = 80 # Number of initial points in NFE array separated by 50 (the rest after that are separated by 100)\n",
    "nfe_array = np.zeros(n_iter_total+1)\n",
    "for i in range(n_iter_init):\n",
    "    nfe_array[i] = 50*i\n",
    "    \n",
    "for i in range(n_iter_total - n_iter_init + 1):\n",
    "    nfe_array[n_iter_init+i] = 50*n_iter_init + 100*i\n",
    "    \n",
    "def nchoosek(n,k):\n",
    "    k = min(k, n-k)\n",
    "    num = reduce(op.mul, range(n,n-k,-1), 1)\n",
    "    den = reduce(op.mul, range(1,k+1), 1)\n",
    "    return num/den    \n",
    "    \n",
    "def get_true_objectives(true_obj1_array, true_obj2_array, index):\n",
    "    return true_obj1_array[index], true_obj2_array[index]\n",
    "\n",
    "def find_last_index(val,search_list):\n",
    "    if val in search_list:\n",
    "        idx = len(search_list) - search_list[::-1].index(val) - 1\n",
    "    else:\n",
    "        idx = 0\n",
    "    return idx\n",
    "\n",
    "def find_closest_index(val,search_list):\n",
    "    val_diff = np.array(search_list) - val\n",
    "    closest_index = np.argmin(np.abs(val_diff))\n",
    "    return closest_index\n",
    "\n",
    "def compute_pareto_front(population):\n",
    "    pop_size = len(population)\n",
    "    obj_num = 2\n",
    "\n",
    "    domination_counter = [0] * pop_size\n",
    "\n",
    "    for i in range(pop_size):\n",
    "        for j in range(i+1, pop_size):\n",
    "            # check each objective for dominance\n",
    "            dominate = [0] * obj_num\n",
    "            for k in range(obj_num):\n",
    "                if population[i][k] > population[j][k]:\n",
    "                    dominate[k] = 1\n",
    "                elif population[i][k] < population[j][k]:\n",
    "                    dominate[k] = -1\n",
    "            if -1 not in dominate and 1 in dominate:\n",
    "                domination_counter[i] += 1\n",
    "            elif -1 in dominate and 1 not in dominate:\n",
    "                domination_counter[j] += 1\n",
    "\n",
    "    pareto_solutions = []\n",
    "    for i in range(len(domination_counter)):\n",
    "        if domination_counter[i] == 0:\n",
    "            pareto_solutions.append(population[i])\n",
    "    return pareto_solutions\n",
    "\n",
    "def compute_hv(population):\n",
    "    array_archs = np.zeros((len(population), 2))\n",
    "    for i in range(len(population)):\n",
    "        array_archs[i] = population[i]\n",
    "    hv_object = hypervolume(array_archs)\n",
    "    hv = hv_object.compute([1.1,1.1])/1.1**2\n",
    "    return hv\n",
    "\n",
    "def get_array_element(array, index):\n",
    "    return array[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Determine csv filepath from given case type for one of the materials problems\n",
    "def get_csv_filepath_material(partcoll_constrained, nodprop_constrained, orient_constrained, inters_constrained, artery_problem, model_choice, run_number):\n",
    "    # partcoll_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # nodprop_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # orient_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # inters_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # artery_problem = True if artery problem data is to be read, False if truss problem data is to be read\n",
    "    # model_choice = 1 - fibre stiffness, 2 - truss stiffness, 3 - ANSYS APDL beam model\n",
    "    \n",
    "    filepath = 'C:\\\\SEAK Lab\\\\SEAK Lab Github\\\\KD3M3\\\\Truss_AOS\\\\result\\\\'\n",
    "    methods = ['Int Pen','AOS','Bias Init','ACH']\n",
    "    heurs_list = ['PartColl','NodalProp','Orient','Inters']\n",
    "    heur_abbrvs_list = ['p','n','o','i']\n",
    "    heur_bools = np.vstack((partcoll_constrained, nodprop_constrained, orient_constrained, inters_constrained))\n",
    "    aos_bools = [x[1] for x in heur_bools]\n",
    "    \n",
    "    if (any(aos_bools)):\n",
    "        filename = 'AOSMOEA_emoea_'\n",
    "    else:\n",
    "        filename = 'EpsilonMOEA_emoea_'\n",
    "    \n",
    "    if artery_problem:\n",
    "        filepath_prob = 'Artery Problem\\\\'\n",
    "        filename_prob = '_artery'\n",
    "    else:\n",
    "        filepath_prob = 'Truss Problem\\\\'\n",
    "        filename_prob = '_prob2'\n",
    "        \n",
    "    filepath_constrad = 'Constant Radii\\\\'\n",
    "        \n",
    "    filepath2 = ''\n",
    "    filename2 = ''\n",
    "    constr_count = 0\n",
    "    for i in range(len(heur_bools)):\n",
    "        constraints = methods[i] + ' - '\n",
    "        constraints_abbrv = ''\n",
    "        heur_count = 0\n",
    "        for j in range(len(heur_bools[0])):\n",
    "            if heur_bools[j][i]:\n",
    "                constraints = constraints + heurs_list[j]\n",
    "                constraints_abbrv = constraints_abbrv + heur_abbrvs_list[j]\n",
    "            else:\n",
    "                heur_count += 1\n",
    "            \n",
    "        if heur_count < len(heur_bools[0]):\n",
    "            filepath2 = filepath2 + constraints + '\\\\'\n",
    "            filename2 = filename2 + constraints_abbrv + 'con' + str(i) + '_'\n",
    "        else:\n",
    "            constr_count += 1\n",
    "            \n",
    "    filepath_moea = ''\n",
    "    if (constr_count == len(heur_bools)):\n",
    "        filepath_moea = 'Epsilon MOEA\\\\'\n",
    "        \n",
    "    if model_choice == 1:\n",
    "        filepath_model = 'Fibre Model\\\\'\n",
    "        filename_model = '_fibre_fullpop.csv'\n",
    "    elif model_choice == 2:\n",
    "        filepath_model = 'Truss Model\\\\'\n",
    "        filename_model = '_truss_fullpop.csv'\n",
    "    elif model_choice == 3:\n",
    "        filepath_model = 'Beam Model\\\\'\n",
    "        filename_model = '_beam_fullpop.csv'\n",
    "        \n",
    "    return filepath + filepath_prob + filepath_constrad + filepath_model + filepath2 + filepath_moea +  filename + str(run_number) + filename2 + filename_prob + filename_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Extract Pareto Front and normalization constants data from csv file\n",
    "def extract_data_from_csv(csv_filepath, artery_problem, intpen_constr_heur, sidenum):\n",
    "    # intpen_constr_heur = [intpen_constr_partcoll, intpen_constr_nodalprop, intpen_constr_orient, intpen_constr_inters] boolean array\n",
    "    n_total_members = int(nchoosek(sidenum**2,2))\n",
    "    with open(csv_filepath,newline='') as csvfile:\n",
    "        data = [row for row in csv.reader(csvfile)]\n",
    "                \n",
    "        num_func_evals_dat = np.zeros(len(data)-1)\n",
    "        pen_obj1_dat = np.zeros(len(data)-1)\n",
    "        pen_obj2_dat = np.zeros(len(data)-1)\n",
    "        true_obj1_dat = np.zeros(len(data)-1)\n",
    "        true_obj2_dat = np.zeros(len(data)-1)\n",
    "        \n",
    "        feas_scores_dat = np.zeros(len(data)-1)\n",
    "        conn_scores_dat = np.zeros(len(data)-1)\n",
    "        if (not artery_problem):\n",
    "            stiffrat_vals_dat = np.zeros(len(data)-1)\n",
    "        partcoll_scores_dat = np.zeros(len(data)-1)\n",
    "        nodprop_scores_dat = np.zeros(len(data)-1)\n",
    "        orient_scores_dat = np.zeros(len(data)-1)\n",
    "        inters_scores_dat = np.zeros(len(data)-1)\n",
    "        \n",
    "        valid_count = 0\n",
    "        for x in range(len(data)-1):\n",
    "            data_float = list(map(float,data[x+1][1:]))\n",
    "            if (any(np.isnan(np.array(data_float))) or any(np.isinf(np.array(data_float)))):\n",
    "                continue\n",
    "            \n",
    "            num_func_evals_dat[valid_count] = int(data[x+1][1])\n",
    "            pen_obj1_dat[valid_count] = float(data[x+1][2])\n",
    "            pen_obj2_dat[valid_count] = float(data[x+1][3])\n",
    "            true_obj1_dat[valid_count] = float(data[x+1][4])\n",
    "            true_obj2_dat[valid_count] = float(data[x+1][5])\n",
    "            \n",
    "            feas_scores_dat[valid_count] = float(data[x+1][6])\n",
    "            conn_scores_dat[valid_count] = float(data[x+1][7])\n",
    "            if (not artery_problem):\n",
    "                stiffrat_vals_dat[valid_count] = float(data[x+1][8])\n",
    "            \n",
    "            partcoll_scores_dat[valid_count] = float(data[x+1][-4])\n",
    "            nodprop_scores_dat[valid_count] = float(data[x+1][-3])\n",
    "            orient_scores_dat[valid_count] = float(data[x+1][-2])\n",
    "            inters_scores_dat[valid_count] = float(data[x+1][-1])\n",
    "    \n",
    "            valid_count += 1\n",
    "            \n",
    "    #designs = designs_dat[:valid_count]\n",
    "    num_func_evals = num_func_evals_dat[:valid_count]\n",
    "    pen_obj1 = pen_obj1_dat[:valid_count]\n",
    "    pen_obj2 = pen_obj2_dat[:valid_count]\n",
    "    true_obj1 = true_obj1_dat[:valid_count]\n",
    "    true_obj2 = true_obj2_dat[:valid_count]\n",
    "    \n",
    "    feas_scores =  feas_scores_dat[:valid_count]\n",
    "    conn_scores = conn_scores_dat[:valid_count]\n",
    "    if (not artery_problem):\n",
    "        stiffrat_vals = stiffrat_vals_dat[:valid_count]\n",
    "    partcoll_scores = partcoll_scores_dat[:valid_count]\n",
    "    nodprop_scores = nodprop_scores_dat[:valid_count]\n",
    "    orient_scores = orient_scores_dat[:valid_count]\n",
    "    inters_scores = inters_scores_dat[:valid_count]\n",
    "            \n",
    "    #print('pen_obj1')\n",
    "    #print(pen_obj1)\n",
    "    #print('\\n')\n",
    "    #print('pen_obj2')\n",
    "    #print(pen_obj2)\n",
    "    #print('\\n')\n",
    "    #print('true_obj1')\n",
    "    #print(true_obj1)\n",
    "    #print('\\n')\n",
    "    #print('true_obj2')\n",
    "    #print(true_obj2)\n",
    "    #print('\\n')\n",
    "    \n",
    "    ## Sort num_fun_evals (and obj1 & obj2, feas and stab scores) in ascending order\n",
    "    n_func_evals = num_func_evals\n",
    "    sort_indices = np.argsort(n_func_evals)\n",
    "    pen_obj1_sorted = list(pen_obj1[sort_indices])\n",
    "    pen_obj2_sorted = list(pen_obj2[sort_indices])\n",
    "    true_obj1_sorted = list(true_obj1[sort_indices])\n",
    "    true_obj2_sorted = list(true_obj2[sort_indices])\n",
    "    \n",
    "    feas_scores_sorted = list(feas_scores[sort_indices])\n",
    "    conn_scores_sorted = list(conn_scores[sort_indices])\n",
    "    if (not artery_problem):\n",
    "        stiffrat_vals_sorted = list(stiffrat_vals[sort_indices])\n",
    "    partcoll_scores_sorted = list(partcoll_scores[sort_indices])\n",
    "    nodprop_scores_sorted = list(nodprop_scores[sort_indices])\n",
    "    orient_scores_sorted = list(orient_scores[sort_indices])\n",
    "    inters_scores_sorted = list(inters_scores[sort_indices])\n",
    "    \n",
    "    #designs_sorted = []\n",
    "    #for i in range(len(sort_indices)):\n",
    "        #designs_sorted.append(designs[sort_indices[i]])\n",
    "    \n",
    "    heur_scores_sorted = np.vstack((partcoll_scores_sorted, nodprop_scores_sorted, orient_scores_sorted, inters_scores_sorted))\n",
    "    \n",
    "    ## Compute only constraint penalized objectives (used for the interior penalty cases)\n",
    "    heur_weight = 1\n",
    "    heur_pen = np.zeros(len(feas_scores_sorted))\n",
    "    if (any(intpen_constr_heur)):\n",
    "        heur_index_array = np.arange(len(intpen_constr_heur))\n",
    "        heur_index_used = [v for i, v in enumerate(heur_index_array) if intpen_constr_heur[i] == True]\n",
    "     \n",
    "        for idx in heur_index_used:\n",
    "            heur_scores_idx = heur_scores_sorted[idx]\n",
    "            heur_pen_idx = [math.log10(abs(x))/16 for x in heur_scores_idx]\n",
    "            heur_pen = np.add(heur_pen,np.divide(heur_pen_idx,len(heur_index_used)))\n",
    "            \n",
    "    #set_trace()\n",
    "    weighted_heur_pen = [k*heur_weight for k in heur_pen]\n",
    "    \n",
    "    pen_obj1_constr_sorted = list(np.add(pen_obj1_sorted,weighted_heur_pen))\n",
    "    pen_obj2_constr_sorted = list(np.add(pen_obj2_sorted,weighted_heur_pen))\n",
    "    \n",
    "    ## Determine normalizing objective scores and compute pareto fronts for penalized and true objectives as well as for true objectives of only feasible designs \n",
    "    nfe_list_sorted = list(n_func_evals[sort_indices])\n",
    "    \n",
    "    #max_func_evals = nfe_list_sorted[-1]\n",
    "    max_func_evals = 6000 # some runs for some cases run upto 5001 evaluations, which causes hv array length issues\n",
    "\n",
    "    pareto_front_dict = {}\n",
    "    #pareto_front_feas_dict = {}\n",
    "    #pareto_front_conn_dict = {}\n",
    "    #pareto_front_stiffrat_dict = {}\n",
    "    #pareto_front_partcoll_dict = {}\n",
    "    #pareto_front_nodprop_dict = {}\n",
    "    #pareto_front_orient_dict = {}\n",
    "    #pareto_front_designs_dict = {}\n",
    "    pareto_front_true_dict = {}\n",
    "    pareto_front_truesat_dict = {}\n",
    "    pf_normalize_max_obj1 = []\n",
    "    pf_normalize_min_obj1 = []\n",
    "    pf_normalize_max_obj2 = []\n",
    "    pf_normalize_min_obj2 = []\n",
    "    pf_true_normalize_max_obj1 = []\n",
    "    pf_true_normalize_min_obj1 = []\n",
    "    pf_true_normalize_max_obj2 = []\n",
    "    pf_true_normalize_min_obj2 = []\n",
    "    pf_truesat_normalize_max_obj1 = []\n",
    "    pf_truesat_normalize_min_obj1 = []\n",
    "    pf_truesat_normalize_max_obj2 = []\n",
    "    pf_truesat_normalize_min_obj2 = []\n",
    "    \n",
    "    count = 0\n",
    "    pop_size = int(find_last_index(0, nfe_list_sorted))\n",
    "    nfe_jump_recorded = False\n",
    "    jump_nfe = 0\n",
    "\n",
    "    for nfe_val in nfe_array:\n",
    "        #print('iter = ' + str(i))\n",
    "    \n",
    "        if (nfe_list_sorted[0] == 0):\n",
    "            if (nfe_val <= 100): # population size set at 100 in java code, but maybe different here due to NaNs\n",
    "                nfe_index_current = pop_size+1\n",
    "            else:\n",
    "                nfe_index_current = find_closest_index(nfe_val, nfe_list_sorted)\n",
    "        else:\n",
    "            if (nfe_val <= nfe_list_sorted[0]):\n",
    "                nfe_index_current = 1\n",
    "            else:\n",
    "                nfe_index_current = find_closest_index(nfe_val, nfe_list_sorted)\n",
    "        \n",
    "        nfe_array_current = nfe_list_sorted[:nfe_index_current]\n",
    "        current_population = []\n",
    "        for j in range(len(nfe_array_current)):\n",
    "            current_population.append([pen_obj1_constr_sorted[j], pen_obj2_constr_sorted[j]])\n",
    "            \n",
    "        #if (\"AOS - Orient\\\\\" in csv_filepath) and (\"emoea_16\" in csv_filepath):\n",
    "            #set_trace()\n",
    "        \n",
    "        current_pareto_front_all = compute_pareto_front(current_population)\n",
    "        #current_pareto_front = list(set(current_pareto_front_all))\n",
    "        current_pareto_front = np.unique(current_pareto_front_all, axis=0)\n",
    "    \n",
    "        current_pareto_feas_scores = []\n",
    "        current_pareto_conn_scores = []\n",
    "        if (not artery_problem):\n",
    "            current_pareto_stiffrat_vals = []\n",
    "        #current_pareto_partcoll_scores = []\n",
    "        #current_pareto_nodprop_scores = []\n",
    "        #current_pareto_orient_scores = []\n",
    "        #current_pareto_designs = []\n",
    "        current_pareto_true_obj = []\n",
    "        current_pareto_truesat_obj = []\n",
    "        for pareto_design in current_pareto_front:\n",
    "            design_index = pen_obj1_constr_sorted.index(pareto_design[0])\n",
    "            design_feas_score = get_array_element(feas_scores_sorted, design_index)\n",
    "            design_conn_score = get_array_element(conn_scores_sorted, design_index)\n",
    "            if (not artery_problem):\n",
    "                design_stiffrat_val = get_array_element(stiffrat_vals_sorted, design_index)\n",
    "            #design_partcoll_score = get_array_element(partcoll_scores_sorted, design_index)\n",
    "            #design_nodprop_score = get_array_element(nodprop_scores_sorted, design_index)\n",
    "            #design_orient_score = get_array_element(orient_scores_sorted, design_index)\n",
    "            current_pareto_feas_scores.append(design_feas_score)\n",
    "            current_pareto_conn_scores.append(design_conn_score)\n",
    "            if (not artery_problem):\n",
    "                current_pareto_stiffrat_vals.append(design_stiffrat_val)\n",
    "            #current_pareto_partcoll_scores.append(design_partcoll_score)\n",
    "            #current_pareto_nodprop_scores.append(design_nodprop_score)\n",
    "            #current_pareto_orient_scores.append(design_orient_score)\n",
    "            #current_pareto_designs.append(get_array_element(designs_sorted, design_index))\n",
    "            \n",
    "            #true_obj1, true_obj2 = compute_true_objectives(pareto_design[0], pareto_design[1], design_feas_score, design_stab_score, fib_stif, intpen_feas_bool, intpen_stab_bool)\n",
    "            true_obj1, true_obj2 = get_true_objectives(true_obj1_sorted, true_obj2_sorted, design_index)\n",
    "        \n",
    "            #set_trace()\n",
    "            \n",
    "            current_pareto_true_obj.append([true_obj1, true_obj2])\n",
    "            \n",
    "            if ((design_feas_score == 1) and (design_conn_score == 1)):\n",
    "                if (not artery_problem):\n",
    "                    if (design_stiffrat_val == 0):\n",
    "                        current_pareto_truesat_obj.append([true_obj1, true_obj2])\n",
    "                else:\n",
    "                    current_pareto_truesat_obj.append([true_obj1, true_obj2])\n",
    "               \n",
    "        if (not current_pareto_truesat_obj):\n",
    "            # purposefully add bad values so that compute_hv function can be used  \n",
    "            if (not artery_problem):\n",
    "                current_pareto_truesat_obj.append([1.8162e6, 1.0])\n",
    "            else:\n",
    "                current_pareto_truesat_obj.append([1.8162e8, 1.0])\n",
    "        \n",
    "        pareto_front_dict[nfe_val] = current_pareto_front\n",
    "        #pareto_front_feas_dict[nfe_val] = current_pareto_feas_scores\n",
    "        #pareto_front_conn_dict[nfe_val] = current_pareto_conn_scores\n",
    "        #pareto_front_stiffrat_dict[nfe_val] = current_pareto_stiffrat_vals\n",
    "        #pareto_front_partcoll_dict[nfe_val] = current_pareto_partcoll_scores\n",
    "        #pareto_front_nodprop_dict[nfe_val] = current_pareto_nodprop_scores\n",
    "        #pareto_front_orient_dict[nfe_val] = current_pareto_orient_scores\n",
    "        #pareto_front_designs_dict[nfe_val] = current_pareto_designs\n",
    "        pareto_front_true_dict[nfe_val] = current_pareto_true_obj\n",
    "        pareto_front_truesat_dict[nfe_val] = current_pareto_truesat_obj\n",
    "        \n",
    "        pf_nfeval_obj1 = [row[0] for row in current_pareto_front]\n",
    "        pf_nfeval_obj2 = [row[1] for row in current_pareto_front]\n",
    "        \n",
    "        pf_true_nfeval_obj1 = [row[0] for row in current_pareto_true_obj]\n",
    "        pf_true_nfeval_obj2 = [row[1] for row in current_pareto_true_obj]\n",
    "        \n",
    "        pf_truesat_nfeval_obj1 = [row[0] for row in current_pareto_truesat_obj]\n",
    "        pf_truesat_nfeval_obj2 = [row[1] for row in current_pareto_truesat_obj]\n",
    "        \n",
    "        pf_normalize_max_obj1.append(np.max(pf_nfeval_obj1))\n",
    "        pf_normalize_min_obj1.append(np.min(pf_nfeval_obj1))\n",
    "        pf_normalize_max_obj2.append(np.max(pf_nfeval_obj2))\n",
    "        pf_normalize_min_obj2.append(np.min(pf_nfeval_obj2))\n",
    "        \n",
    "        pf_true_normalize_max_obj1.append(np.max(pf_true_nfeval_obj1))\n",
    "        pf_true_normalize_min_obj1.append(np.min(pf_true_nfeval_obj1))\n",
    "        pf_true_normalize_max_obj2.append(np.max(pf_true_nfeval_obj2))\n",
    "        pf_true_normalize_min_obj2.append(np.min(pf_true_nfeval_obj2))\n",
    "        \n",
    "        pf_truesat_normalize_max_obj1.append(np.max(pf_truesat_nfeval_obj1))\n",
    "        pf_truesat_normalize_min_obj1.append(np.min(pf_truesat_nfeval_obj1))\n",
    "        pf_truesat_normalize_max_obj2.append(np.max(pf_truesat_nfeval_obj2))\n",
    "        pf_truesat_normalize_min_obj2.append(np.min(pf_truesat_nfeval_obj2))\n",
    "    \n",
    "        #nonzero_feas_scores = True in (feas_score > 0.1 for feas_score in current_pareto_feas_scores)\n",
    "        #if (nonzero_feas_scores):\n",
    "            #if (not nfe_jump_recorded):\n",
    "                #jump_nfe = i\n",
    "                #nfe_jump_recorded = True\n",
    "        \n",
    "            #pareto_obj1s = [pareto_design[0] for pareto_design in current_pareto_front]\n",
    "            #pareto_obj2s = [pareto_design[1] for pareto_design in current_pareto_front]\n",
    "        \n",
    "            #if (np.max(pareto_obj1s) > obj1_normalize_max_afterjump):\n",
    "                #obj1_normalize_max_afterjump = np.max(pareto_obj1s)\n",
    "        \n",
    "            #if (np.max(pareto_obj2s) > obj2_normalize_max_afterjump):\n",
    "                #obj2_normalize_max_afterjump = np.max(pareto_obj2s)\n",
    "        \n",
    "            #if (np.min(pareto_obj1s) < obj1_normalize_min_afterjump):\n",
    "                #obj1_normalize_min_afterjump = np.min(pareto_obj1s)\n",
    "        \n",
    "            #if (np.min(pareto_obj2s) < obj2_normalize_min_afterjump):\n",
    "                #obj2_normalize_min_afterjump = np.min(pareto_obj2s)\n",
    "\n",
    "    ### Computing obj_normalize_fullrun, obj_normalize_afterjump and obj_normalized_true_fullrun using the entire run \n",
    "    #obj_normalize_max_fullrun = [np.max(pen_obj1_constr_sorted), np.max(pen_obj2_constr_sorted)]\n",
    "    #obj_normalize_min_fullrun = [np.min(pen_obj1_constr_sorted), np.min(pen_obj2_constr_sorted)]\n",
    "\n",
    "    #obj_true_normalize_max_fullrun = [np.max(true_obj1_sorted), np.max(true_obj2_sorted)]\n",
    "    #obj_true_normalize_min_fullrun = [np.min(true_obj1_sorted), np.min(true_obj2_sorted)]\n",
    "\n",
    "    # shift to above for loop if afterjump condition is used\n",
    "    #obj1_normalize_max_afterjump = 0\n",
    "    #obj1_normalize_min_afterjump = 0\n",
    "    #obj2_normalize_max_afterjump = 0\n",
    "    #obj2_normalize_min_afterjump = 0\n",
    "    \n",
    "    #obj_normalize_max_afterjump = [obj1_normalize_max_afterjump, obj2_normalize_max_afterjump]\n",
    "    #obj_normalize_min_afterjump = [obj1_normalize_min_afterjump, obj2_normalize_min_afterjump]\n",
    "    \n",
    "    #obj_normalize_fullrun = [obj_normalize_min_fullrun, obj_normalize_max_fullrun]\n",
    "    #obj_normalize_afterjump = [obj_normalize_min_afterjump, obj_normalize_max_afterjump]\n",
    "    #obj_normalize_true_fullrun = [obj_true_normalize_min_fullrun, obj_true_normalize_max_fullrun]\n",
    "    \n",
    "    ### Computing obj_normalize_fullrun, obj_normalize_afterjump and obj_normalized_true_fullrun using the pareto fronts    \n",
    "    obj_normalize_max_fullrun = [np.max(pf_normalize_max_obj1), np.max(pf_normalize_max_obj2)]\n",
    "    obj_normalize_min_fullrun = [np.min(pf_normalize_min_obj1), np.min(pf_normalize_min_obj2)]\n",
    "    \n",
    "    obj_true_normalize_max_fullrun = [np.max(pf_true_normalize_max_obj1), np.max(pf_true_normalize_max_obj2)]\n",
    "    obj_true_normalize_min_fullrun = [np.min(pf_true_normalize_min_obj1), np.min(pf_true_normalize_min_obj2)]\n",
    "    \n",
    "    obj_truesat_normalize_max_fullrun = [np.max(pf_truesat_normalize_max_obj1), np.max(pf_truesat_normalize_max_obj2)]\n",
    "    obj_truesat_normalize_min_fullrun = [np.min(pf_truesat_normalize_min_obj1), np.min(pf_truesat_normalize_min_obj2)]\n",
    "\n",
    "    obj_normalize_fullrun = [obj_normalize_min_fullrun, obj_normalize_max_fullrun]\n",
    "    obj_normalize_true_fullrun = [obj_true_normalize_min_fullrun, obj_true_normalize_max_fullrun]\n",
    "    obj_normalize_truesat_fullrun = [obj_truesat_normalize_min_fullrun, obj_truesat_normalize_max_fullrun]\n",
    "    \n",
    "    return pareto_front_dict, pareto_front_true_dict, pareto_front_truesat_dict, obj_normalize_fullrun, obj_normalize_true_fullrun, obj_normalize_truesat_fullrun, max_func_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute overall normalization objectives for single case study/all compared case studies (from the complete runs)\n",
    "def compute_overall_norm_objs(objs_normalization_full, objs_normalization_true, objs_normalization_truesat):\n",
    "    # Each input is a dictionary with key as the case study/run string and value as the corresponding 2D array\n",
    "    \n",
    "    obj1_max_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj1_min_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj2_max_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj2_min_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj1_max_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    obj1_min_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    obj2_max_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    obj2_min_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    obj1_max_truesat_allcases = np.zeros(len(objs_normalization_truesat))\n",
    "    obj1_min_truesat_allcases = np.zeros(len(objs_normalization_truesat))\n",
    "    obj2_max_truesat_allcases = np.zeros(len(objs_normalization_truesat))\n",
    "    obj2_min_truesat_allcases = np.zeros(len(objs_normalization_truesat))\n",
    "    \n",
    "    i = 0\n",
    "    for key in objs_normalization_full:\n",
    "        current_objs_norm_full = objs_normalization_full[key]\n",
    "        \n",
    "        obj1_max_full_allcases[i] = current_objs_norm_full[1][0]\n",
    "        obj2_max_full_allcases[i] = current_objs_norm_full[1][1]\n",
    "        obj1_min_full_allcases[i] = current_objs_norm_full[0][0]\n",
    "        obj2_min_full_allcases[i] = current_objs_norm_full[0][1]\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    for key2 in objs_normalization_true:\n",
    "        current_objs_norm_true = objs_normalization_true[key2]\n",
    "        \n",
    "        obj1_max_true_allcases[i] = current_objs_norm_true[1][0]\n",
    "        obj2_max_true_allcases[i] = current_objs_norm_true[1][1]\n",
    "        obj1_min_true_allcases[i] = current_objs_norm_true[0][0]\n",
    "        obj2_min_true_allcases[i] = current_objs_norm_true[0][1]\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    for key3 in objs_normalization_truesat:\n",
    "        current_objs_norm_truesat = objs_normalization_truesat[key3]\n",
    "        \n",
    "        obj1_max_truesat_allcases[i] = current_objs_norm_truesat[1][0]\n",
    "        obj2_max_truesat_allcases[i] = current_objs_norm_truesat[1][1]\n",
    "        obj1_min_truesat_allcases[i] = current_objs_norm_truesat[0][0]\n",
    "        obj2_min_truesat_allcases[i] = current_objs_norm_truesat[0][1]\n",
    "        i += 1\n",
    "        \n",
    "    obj1_min_full_overall = np.min(obj1_min_full_allcases)\n",
    "    obj2_min_full_overall = np.min(obj2_min_full_allcases)\n",
    "    obj1_max_full_overall = np.max(obj1_max_full_allcases)\n",
    "    obj2_max_full_overall = np.max(obj2_max_full_allcases)\n",
    "    \n",
    "    obj1_min_true_overall = np.min(obj1_min_true_allcases)\n",
    "    obj2_min_true_overall = np.min(obj2_min_true_allcases)\n",
    "    obj1_max_true_overall = np.max(obj1_max_true_allcases)\n",
    "    obj2_max_true_overall = np.max(obj2_max_true_allcases)\n",
    "    \n",
    "    obj1_min_truesat_overall = np.min(obj1_min_truesat_allcases)\n",
    "    obj2_min_truesat_overall = np.min(obj2_min_truesat_allcases)\n",
    "    obj1_max_truesat_overall = np.max(obj1_max_truesat_allcases)\n",
    "    obj2_max_truesat_overall = np.max(obj2_max_truesat_allcases)\n",
    "            \n",
    "    obj_norm_full_overall = [[obj1_min_full_overall, obj2_min_full_overall], [obj1_max_full_overall, obj2_max_full_overall]]\n",
    "    obj_norm_true_overall = [[obj1_min_true_overall, obj2_min_true_overall], [obj1_max_true_overall, obj2_max_true_overall]]    \n",
    "    obj_norm_truesat_overall = [[obj1_min_truesat_overall, obj2_min_truesat_overall], [obj1_max_truesat_overall, obj2_max_truesat_overall]]    \n",
    "    \n",
    "    return obj_norm_full_overall, obj_norm_true_overall, obj_norm_truesat_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute hypervolume arrays from copmuted pareto fronts and normalization constants\n",
    "def compute_hv_arrays_from_csv_data(pf_dict, pf_true_dict, pf_truesat_dict, obj_norm_full, obj_norm_true_full, obj_norm_truesat_full, max_fun_evals):\n",
    "    obj_norm_min_full = obj_norm_full[0]\n",
    "    obj_norm_max_full = obj_norm_full[1]\n",
    "    obj_norm_true_min_full = obj_norm_true_full[0]\n",
    "    obj_norm_true_max_full = obj_norm_true_full[1]\n",
    "    obj_norm_truesat_min_full = obj_norm_truesat_full[0]\n",
    "    obj_norm_truesat_max_full = obj_norm_truesat_full[1]\n",
    "\n",
    "    ## Normalize the pareto front objectives and compute the hypervolume\n",
    "    hypervol_full_dict = []\n",
    "    hypervol_true_full_dict = []\n",
    "    hypervol_truesat_full_dict = []\n",
    "\n",
    "    for nfe_val in nfe_array:\n",
    "        #print('iter = ' + str(nfe_val))\n",
    "    \n",
    "        current_pareto_front = pf_dict[nfe_val]\n",
    "        current_true_pareto_front = pf_true_dict[nfe_val]\n",
    "        current_truesat_pareto_front = pf_truesat_dict[nfe_val]\n",
    "        current_pf_normalized = []\n",
    "        current_pf_true_normalized = []\n",
    "        current_pf_truesat_normalized = []\n",
    "        for pareto_design in current_pareto_front:\n",
    "            obj1_normalized = (pareto_design[0] - obj_norm_min_full[0])/(obj_norm_max_full[0] - obj_norm_min_full[0])\n",
    "            obj2_normalized = (pareto_design[1] - obj_norm_min_full[1])/(obj_norm_max_full[1] - obj_norm_min_full[1])\n",
    "            current_pf_normalized.append([obj1_normalized, obj2_normalized])\n",
    "            \n",
    "        for pareto_design_true in current_true_pareto_front:\n",
    "            obj1_true_normalized = (obj_norm_true_max_full[0] - pareto_design_true[0])/(obj_norm_true_max_full[0] - obj_norm_true_min_full[0])\n",
    "            obj2_true_normalized = (pareto_design_true[1] - obj_norm_true_min_full[1])/(obj_norm_true_max_full[1] - obj_norm_true_min_full[1])\n",
    "            current_pf_true_normalized.append([obj1_true_normalized, obj2_true_normalized])\n",
    "            \n",
    "        for pareto_design_truesat in current_truesat_pareto_front:\n",
    "            obj1_truesat_normalized = (obj_norm_truesat_max_full[0] - pareto_design_truesat[0])/(obj_norm_truesat_max_full[0] - obj_norm_truesat_min_full[0])\n",
    "            obj2_truesat_normalized = (pareto_design_truesat[1] - obj_norm_truesat_min_full[1])/(obj_norm_truesat_max_full[1] - obj_norm_truesat_min_full[1])\n",
    "            current_pf_truesat_normalized.append([obj1_truesat_normalized, obj2_truesat_normalized])\n",
    "            \n",
    "        current_hv = compute_hv(current_pf_normalized)\n",
    "        hypervol_full_dict.append([nfe_val, current_hv])\n",
    "        \n",
    "        current_hv_true = compute_hv(current_pf_true_normalized)\n",
    "        hypervol_true_full_dict.append([nfe_val, current_hv_true])\n",
    "        \n",
    "        #set_trace()\n",
    "        current_hv_truesat = compute_hv(current_pf_truesat_normalized)\n",
    "        hypervol_truesat_full_dict.append([nfe_val, current_hv_truesat])\n",
    "        \n",
    "    return hypervol_full_dict, hypervol_true_full_dict, hypervol_truesat_full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute array of NFE values for reaching threshold hypervolume for different runs of a particular case\n",
    "def compute_nfe_hypervolume_attained(hv_dict, hv_threshold):\n",
    "    #hv_threshold = 0.75 # Threshold HV value to reach, user parameter\n",
    "    n_runs = len(hv_dict)\n",
    "    nfe_hv_attained = []\n",
    "    for key in hv_dict:\n",
    "        hv_array_run = hv_dict[key]\n",
    "        nfe_array_run = [hv_array[0] for hv_array in hv_array_run]\n",
    "        hv_val_array = [hv_array[1] for hv_array in hv_array_run]\n",
    "        nfe_hv_attained_run = nfe_array_run[-1] + 100\n",
    "        for i in range(len(hv_val_array)):\n",
    "            if (hv_val_array[i] >= hv_threshold):\n",
    "                nfe_hv_attained_run = nfe_array_run[i]\n",
    "                break\n",
    "                \n",
    "        #hv_val_diff = [np.abs(x - hv_threshold) for x in hv_val_array]\n",
    "        #index = np.argmin(hv_val_diff)\n",
    "        nfe_hv_attained.append(nfe_hv_attained_run)\n",
    "        \n",
    "    return nfe_hv_attained\n",
    "    \n",
    "### Plot fraction of runs attaining threshold hypervolume vs NFE\n",
    "def plot_fraction_hypervolume_attained(nfe_hv_attained_dict, nfe_array, colour_array, casename_array, savefig_name, hv_threshold):\n",
    "    fig1 = plt.figure(1)\n",
    "    n_cases = len(nfe_hv_attained_dict)\n",
    "    case_idx = 0\n",
    "    for case_key in nfe_hv_attained_dict:\n",
    "        nfe_hv_attained_case = nfe_hv_attained_dict[case_key]\n",
    "        n_runs = len(nfe_hv_attained_case)\n",
    "        frac_runs_hv_attained = np.zeros(len(nfe_array))\n",
    "        for i in range(len(nfe_array)):\n",
    "            idx_runs_hv_attained = [idx for idx, val in enumerate(nfe_hv_attained_case) if val <= nfe_array[i]]\n",
    "            frac_runs_hv_attained[i] = len(idx_runs_hv_attained)/n_runs\n",
    "            \n",
    "        plt.plot(nfe_array, frac_runs_hv_attained, '-', color=colour_array[case_idx], label=casename_array[case_idx])\n",
    "        case_idx += 1\n",
    "    \n",
    "    plt.xlabel('Number of Function Evaluations',fontsize=14)\n",
    "    plt.ylabel('Fraction of runs HV $\\geq$ ' + str(hv_threshold),fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.20), ncol=3, borderaxespad=0 ,prop={\"size\":12})\n",
    "    plt.show()\n",
    "    fig1.savefig('frac_hv_attained_' + savefig_name + '.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hypervolume_stats(hypervols_dict):\n",
    "    hv_dict_keys = list(hypervols_dict.keys())\n",
    "    hv_dict_0 = hypervols_dict[hv_dict_keys[0]]\n",
    "    nfe_array_0 = [hv_array[0] for hv_array in hv_dict_0]\n",
    "    n_datapoints = len(nfe_array_0)\n",
    "    hypervol_median = np.zeros(n_datapoints)\n",
    "    hypervol_1q = np.zeros(n_datapoints)\n",
    "    hypervol_3q = np.zeros(n_datapoints)\n",
    "    for i in range(n_datapoints):\n",
    "        hypervol_vals = []\n",
    "        for key in hypervols_dict:\n",
    "            hv_dict_j = hypervols_dict[key]\n",
    "            hv_current_array = [hv_array[1] for hv_array in hv_dict_j]\n",
    "            hypervol_vals.append(hv_current_array[i])\n",
    "        hypervol_median[i] = statistics.median(hypervol_vals)\n",
    "        #hypervol_median[i] = statistics.mean(hypervol_vals)\n",
    "        hypervol_1q[i] = np.percentile(hypervol_vals, 25)\n",
    "        #hypervol_1q[i] = hypervol_median[i] - statistics.stdev(hypervol_vals)\n",
    "        hypervol_3q[i] = np.percentile(hypervol_vals, 75)\n",
    "        #hypervol_3q[i] = hypervol_median[i] + statistics.stdev(hypervol_vals)\n",
    "        \n",
    "    return hypervol_median, hypervol_1q, hypervol_3q, nfe_array_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mann_whitney_Uvals(hv_med_dict_allcases, nfe_array): # Wilcoxon Rank Sum Test\n",
    "    # hv_med_array_allcases is a dictionary of length = number of cases\n",
    "    n_samples = 20\n",
    "    linspace_samples_array = np.linspace(0,1,n_samples)\n",
    "    nfe_samples_array = np.floor(np.multiply(linspace_samples_array, nfe_array[-1]))\n",
    "    nfe_samples_indices_array = np.zeros(len(nfe_samples_array))\n",
    "    for i in range(len(nfe_samples_array)):\n",
    "        nfe_samples_indices_array[i] = find_closest_index(nfe_samples_array[i], nfe_array)\n",
    "        \n",
    "    hv_med_samples_allcases = {}\n",
    "    for j in range(len(hv_med_dict_allcases)):\n",
    "        hv_med_case = hv_med_array_allcases['case'+str(i)]\n",
    "        hv_med_samples_case = np.zeros(len(hv_med_case))\n",
    "        for k in range(len(hv_med_case)):\n",
    "            hv_med_samples_case[k] = hv_med_case[nfe_samples_indices_array[k]]\n",
    "        hv_med_samples_allcases['case'+str(i)] = hv_med_samples_case\n",
    "        \n",
    "    cases_array = np.arange(len(hv_med_array_allcases))\n",
    "    case_combinations = list(combinations(cases_array,2))\n",
    "    \n",
    "    U_test_cases = {}\n",
    "    \n",
    "    for k in range(len(case_combinations)):\n",
    "        case_string_x = 'case' + str(case_combinations[k][0])\n",
    "        case_string_y = 'case' + str(case_combinations[k][1])\n",
    "        \n",
    "        U1, p = mannwhitneyu(hv_med_samples_allcases[case_string_x], hv_med_samples_allcases[case_string_y])\n",
    "        U2 = len(hv_med_samples_allcases[case_string_x])*len(hv_med_samples_allcases[case_string_y]) - U1\n",
    "        \n",
    "        U_test = np.min(np.array([U1, U2]))\n",
    "        dict_key = case_string_x + ' and ' + case_string_y\n",
    "        \n",
    "        U_test_cases[dict_key] = [U_test, p]\n",
    "        \n",
    "    return U_test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hypervolume_stats(hv_median_case, hv_1q_case, hv_3q_case, nfe_array, savefig_name):\n",
    "    fig1 = plt.figure(1)\n",
    "    plt.plot(nfe_array,hv_median_case, 'b-', label='Median')\n",
    "    plt.plot(nfe_array,hv_1q_case, 'r-', label='1st Quartile')\n",
    "    plt.plot(nfe_array,hv_3q_case, 'g-', label='3rd Quartile')\n",
    "    plt.xlabel('Number of Function Evaluations')\n",
    "    plt.ylabel('Hypervolume')\n",
    "    plt.title('Averaged Hypervolume vs NFE')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    #fig1.savefig('HV_plot_averaged_' + savefig_name + '.png')\n",
    "    \n",
    "def plot_hypervolume_stats_allcases(hv_median_dict, hv_1q_dict, hv_3q_dict, nfe_array, colour_array, alpha_array, casename_array, plot_title, savefig_name):\n",
    "    fig1 = plt.figure(1)\n",
    "    number_cases = len(hv_median_dict)\n",
    "    #print('n_cases')\n",
    "    #print(number_cases)\n",
    "    for i in range(number_cases):\n",
    "        #print(print(marker_array[i]+'*'))\n",
    "        plt.plot(nfe_array, hv_median_dict['case'+str(i)], '-', color=colour_array[i], label=casename_array[i])\n",
    "        plt.fill_between(nfe_array, hv_1q_dict['case'+str(i)], hv_3q_dict['case'+str(i)], color=colour_array[i], alpha=alpha_array[i])\n",
    "        \n",
    "        #plt.plot(nfe_array, hv_1q_dict['case'+str(i)], '--', color=colour_array[i])#, label=casename_array[i]+' 1st Quartile')\n",
    "        #plt.plot(nfe_array, hv_3q_dict['case'+str(i)], '--', color=colour_array[i])#, label=casename_array[i]+' 3rd Quartile')\n",
    "    plt.xlabel('Number of Function Evaluations',fontsize=14)\n",
    "    plt.ylabel('Hypervolume',fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    #plt.title(plot_title)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.20), ncol=3, borderaxespad=0, prop={\"size\":12})\n",
    "    plt.show()\n",
    "    fig1.savefig('HV_plot_averaged_' + savefig_name + '.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define functions to compute and plot hypervolume for single case and all cases\n",
    "def hypervolume_computation_single_case(choice_model, case_booleans, prob_artery, sidenum, run_nums, case_name):\n",
    "    ## Computing the pareto fronts and normalization objectives for each run\n",
    "    obj_norm_allruns = {}\n",
    "    obj_norm_true_allruns = {}\n",
    "    obj_norm_truesat_allruns = {}\n",
    "    pf_allruns = {}\n",
    "    pf_true_allruns = {}\n",
    "    pf_truesat_allruns = {}\n",
    "    max_f_evals_allruns = np.zeros(run_nums)\n",
    "    for i in range(run_nums):\n",
    "        print('Computing Pareto Fronts for run ' + str(i))\n",
    "        current_csvpath = get_csv_filepath_material(case_booleans[:4], case_booleans[4:8], case_booleans[8:12], case_booleans[12:16], prob_artery, choice_model, i)\n",
    "        heur_intpen_constr = [case_booleans[0], case_booleans[4], case_booleans[8], case_booleans[12]]\n",
    "        pf_dict_i, pf_true_dict_i, pf_truesat_dict_i, obj_norm_full_i, obj_norm_true_i, obj_norm_truesat_i, max_fun_evals_i = extract_data_from_csv(current_csvpath, prob_artery, heur_intpen_constr, sidenum)\n",
    "        #set_trace()\n",
    "        pf_allruns['run'+str(i)] = pf_dict_i\n",
    "        pf_true_allruns['run'+str(i)] = pf_true_dict_i\n",
    "        pf_truesat_allruns['run'+str(i)] = pf_truesat_dict_i\n",
    "        obj_norm_allruns['run'+str(i)] = obj_norm_full_i\n",
    "        obj_norm_true_allruns['run'+str(i)] = obj_norm_true_i\n",
    "        obj_norm_truesat_allruns['run'+str(i)] = obj_norm_truesat_i\n",
    "        max_f_evals_allruns[i] = max_fun_evals_i\n",
    "    \n",
    "    #print('pf_allruns')\n",
    "    #print(pf_allruns)\n",
    "    #print('\\n')\n",
    "    #print('pf_true_allruns')\n",
    "    #print(pf_true_allruns)\n",
    "    #print('\\n')\n",
    "    ## Use computed normalization objectives and find the overall normalization objectives across all runs\n",
    "    print('Computing overall normalization constants')\n",
    "    norm_objs_full_overall, norm_objs_true_overall, norm_objs_truesat_overall = compute_overall_norm_objs(obj_norm_allruns, obj_norm_true_allruns, obj_norm_truesat_allruns)\n",
    "    #set_trace()\n",
    "    #print('norm_objs_full_overall')\n",
    "    #print(norm_objs_full_overall)\n",
    "    #print('\\n')\n",
    "    #print('norm_objs_true_overall')\n",
    "    #print(norm_objs_true_overall)\n",
    "    #print('\\n')\n",
    "    \n",
    "    ## Compute Hypervolume values for each run\n",
    "    hv_dict_allruns = {}\n",
    "    #hv_dict_aj_allruns = {}\n",
    "    hv_dict_true_allruns = {}\n",
    "    hv_dict_truesat_allruns = {}\n",
    "    for j in range(run_nums):\n",
    "        print('Computing hypervolume values for run ' + str(j))\n",
    "        hv_dict_j, hv_dict_true_j, hv_dict_truesat_j = compute_hv_arrays_from_csv_data(pf_allruns['run'+str(j)], pf_true_allruns['run'+str(j)], pf_truesat_allruns['run'+str(j)], norm_objs_full_overall, norm_objs_true_overall, norm_objs_truesat_overall, max_f_evals_allruns[j])\n",
    "        hv_dict_allruns['run'+str(j)] = hv_dict_j\n",
    "        hv_dict_true_allruns['run'+str(j)] = hv_dict_true_j\n",
    "        hv_dict_truesat_allruns['run'+str(j)] = hv_dict_truesat_j\n",
    "        \n",
    "    #print('hv_dict_allruns')\n",
    "    #print(hv_dict_allruns)\n",
    "    #print('hv_dict_true_allruns')\n",
    "    #print(hv_dict_true_allruns)\n",
    "        \n",
    "    ## Plotting\n",
    "    print('Plotting')\n",
    "    hv_median_all, hv_1q_all, hv_3q_all, nfe_array = compute_hypervolume_stats(hv_dict_allruns)\n",
    "    plot_hypervolume_stats(hv_median_all, hv_1q_all, hv_3q_all, nfe_array, case_name+'_full')\n",
    "\n",
    "    ## Plot HVs for true objectives\n",
    "    hv_true_median_all, hv_true_1q_all, hv_true_3q_all, nfe_array_true = compute_hypervolume_stats(hv_dict_true_allruns)\n",
    "    plot_hypervolume_stats(hv_true_median_all, hv_true_1q_all, hv_true_3q_all, nfe_array_true, case_name+'_true')\n",
    "    \n",
    "    ## Plot HVs for truesat objectives\n",
    "    hv_truesat_median_all, hv_truesat_1q_all, hv_truesat_3q_all, nfe_array_truesat = compute_hypervolume_stats(hv_dict_truesat_allruns)\n",
    "    plot_hypervolume_stats(hv_truesat_median_all, hv_truesat_1q_all, hv_truesat_3q_all, nfe_array_truesat, case_name+'_truesat')\n",
    "    \n",
    "def hypervolume_computation_all_cases(choice_model, case_bools_dict, prob_artery, sidenum, run_nums, marker_colours, alpha_vals, case_names, hv_thresh):\n",
    "    num_cases = len(case_bools_dict) # number of cases to compare \n",
    "\n",
    "    ## Computing the pareto fronts and normalization objectives for each run in each case\n",
    "    pf_allcases = {}\n",
    "    pf_true_allcases = {}\n",
    "    pf_truesat_allcases = {}\n",
    "    obj_norm_allcasesandruns = {}\n",
    "    obj_norm_true_allcasesandruns = {}\n",
    "    obj_norm_truesat_allcasesandruns = {}\n",
    "    max_f_evals_allcases = {}\n",
    "    for i in range(num_cases):\n",
    "        print('Computing Pareto Fronts for runs in Case '+str(i))\n",
    "        current_case_bools = case_bools_dict['case'+str(i+1)]\n",
    "        #set_trace()\n",
    "        pf_allruns_i = {}\n",
    "        pf_true_allruns_i = {}\n",
    "        pf_truesat_allruns_i = {}\n",
    "        max_f_evals_allruns = np.zeros(run_nums)\n",
    "        for j in range(run_nums):\n",
    "            print('Run '+str(j))\n",
    "            current_csvpath = get_csv_filepath_material(current_case_bools[:4], current_case_bools[4:8], current_case_bools[8:12], current_case_bools[12:16], prob_artery, choice_model, j)\n",
    "            #set_trace()\n",
    "            heur_intpen_constr = [current_case_bools[0], current_case_bools[4], current_case_bools[8], current_case_bools[12]]\n",
    "            pf_dict_j, pf_true_dict_j, pf_truesat_dict_j, obj_norm_full_j, obj_norm_true_j, obj_norm_truesat_j, max_fun_evals_j = extract_data_from_csv(current_csvpath, prob_artery, heur_intpen_constr, sidenum)\n",
    "            #set_trace()\n",
    "            pf_allruns_i['run'+str(j)] = pf_dict_j\n",
    "            pf_true_allruns_i['run'+str(j)] = pf_true_dict_j\n",
    "            pf_truesat_allruns_i['run'+str(j)] = pf_truesat_dict_j\n",
    "            obj_norm_allcasesandruns['case'+str(i+1)+'run'+str(j)] = obj_norm_full_j\n",
    "            obj_norm_true_allcasesandruns['case'+str(i+1)+'run'+str(j)] = obj_norm_true_j\n",
    "            obj_norm_truesat_allcasesandruns['case'+str(i+1)+'run'+str(j)] = obj_norm_truesat_j\n",
    "            max_f_evals_allruns[j] = max_fun_evals_j\n",
    "        pf_allcases['case'+str(i+1)] = pf_allruns_i\n",
    "        pf_true_allcases['case'+str(i+1)] = pf_true_allruns_i\n",
    "        pf_truesat_allcases['case'+str(i+1)] = pf_truesat_allruns_i\n",
    "        max_f_evals_allcases['case'+str(i+1)] = max_f_evals_allruns\n",
    "    \n",
    "    ## Use computed normalization objectives and find the overall normalization objectives across all runs and cases\n",
    "    print('Computing overall normalization constants')\n",
    "    norm_objs_full_overall, norm_objs_true_overall, norm_objs_truesat_overall = compute_overall_norm_objs(obj_norm_allcasesandruns, obj_norm_true_allcasesandruns, obj_norm_truesat_allcasesandruns)\n",
    "    #set_trace()\n",
    "    \n",
    "    ## Compute Hypervolume values for each run in each case\n",
    "    hv_dict_median_allcases = {}\n",
    "    hv_dict_1q_allcases = {}\n",
    "    hv_dict_3q_allcases = {}\n",
    "    #hv_dict_aj_median_allcases = {}\n",
    "    #hv_dict_aj_1q_allcases = {}\n",
    "    #hv_dict_aj_3q_allcases = {}\n",
    "    hv_dict_true_median_allcases = {}\n",
    "    hv_dict_true_1q_allcases = {}\n",
    "    hv_dict_true_3q_allcases = {}\n",
    "    hv_dict_truesat_median_allcases = {}\n",
    "    hv_dict_truesat_1q_allcases = {}\n",
    "    hv_dict_truesat_3q_allcases = {}\n",
    "    nfe_array_hv_attained_dict = {}\n",
    "    for i in range(num_cases):\n",
    "        print('Computing hypervolume values for runs in Case '+str(i))\n",
    "        pfs_case_i = pf_allcases['case'+str(i+1)]\n",
    "        pfs_true_case_i = pf_true_allcases['case'+str(i+1)]\n",
    "        pfs_truesat_case_i = pf_truesat_allcases['case'+str(i+1)]\n",
    "        max_func_evals_i = max_f_evals_allcases['case'+str(i+1)]\n",
    "        hv_dict_allruns = {}\n",
    "        hv_dict_true_allruns = {}\n",
    "        hv_dict_truesat_allruns = {}\n",
    "        for j in range(run_nums):\n",
    "            print('Run '+str(j))\n",
    "            hv_dict_j, hv_dict_true_j, hv_dict_truesat_j = compute_hv_arrays_from_csv_data(pfs_case_i['run'+str(j)], pfs_true_case_i['run'+str(j)], pfs_truesat_case_i['run'+str(j)], norm_objs_full_overall, norm_objs_true_overall, norm_objs_truesat_overall, max_func_evals_i[j])\n",
    "            hv_dict_allruns['run'+str(j)] = hv_dict_j\n",
    "            hv_dict_true_allruns['run'+str(j)] = hv_dict_true_j\n",
    "            hv_dict_truesat_allruns['run'+str(j)] = hv_dict_truesat_j\n",
    "            \n",
    "        print('Computing array of NFE for attaining threshold hypervolume')\n",
    "        nfe_hv_attained_case = compute_nfe_hypervolume_attained(hv_dict_allruns, hv_thresh)\n",
    "        nfe_array_hv_attained_dict['case'+str(i)] = nfe_hv_attained_case\n",
    "                \n",
    "        print('Computing hypervolume stats')\n",
    "        hv_med_i, hv_1q_i, hv_3q_i, nfe_array_i = compute_hypervolume_stats(hv_dict_allruns)\n",
    "        hv_med_true_i, hv_1q_true_i, hv_3q_true_i, nfe_array_true_i = compute_hypervolume_stats(hv_dict_true_allruns)\n",
    "        hv_med_truesat_i, hv_1q_truesat_i, hv_3q_truesat_i, nfe_array_truesat_i = compute_hypervolume_stats(hv_dict_truesat_allruns)\n",
    "        \n",
    "        hv_dict_median_allcases['case'+str(i)] = hv_med_i\n",
    "        hv_dict_1q_allcases['case'+str(i)] = hv_1q_i\n",
    "        hv_dict_3q_allcases['case'+str(i)] = hv_3q_i\n",
    "        hv_dict_true_median_allcases['case'+str(i)] = hv_med_true_i\n",
    "        hv_dict_true_1q_allcases['case'+str(i)] = hv_1q_true_i\n",
    "        hv_dict_true_3q_allcases['case'+str(i)] = hv_3q_true_i\n",
    "        hv_dict_truesat_median_allcases['case'+str(i)] = hv_med_truesat_i\n",
    "        hv_dict_truesat_1q_allcases['case'+str(i)] = hv_1q_truesat_i\n",
    "        hv_dict_truesat_3q_allcases['case'+str(i)] = hv_3q_truesat_i\n",
    "        \n",
    "    U_test_dict = compute_mann_whitney_Uvals(hv_dict_median_allcases, nfe_array_i)\n",
    "    U_test_truesat_dict = compute_mann_whitney_Uvals(hv_dict_truesat_median_allcases, nfe_array_truesat_i)\n",
    "    \n",
    "    #return nfe_array_hv_attained_dict, hv_dict_median_allcases, hv_dict_1q_allcases, hv_dict_3q_allcases, hv_dict_true_median_allcases, hv_dict_true_1q_allcases, hv_dict_true_3q_allcases, hv_dict_truesat_median_allcases, hv_dict_truesat_1q_allcases, hv_dict_truesat_3q_allcases, nfe_array_i\n",
    "    return nfe_array_hv_attained_dict, hv_dict_median_allcases, hv_dict_1q_allcases, hv_dict_3q_allcases, hv_dict_true_median_allcases, hv_dict_true_1q_allcases, hv_dict_true_3q_allcases, hv_dict_truesat_median_allcases, hv_dict_truesat_1q_allcases, hv_dict_truesat_3q_allcases, U_test, U_test_truesat, nfe_array_i\n",
    "    \n",
    "def plotting_all_cases(nfe_hv_attained_dict, hv_dict_med_allcases, hv_dict_1stq_allcases, hv_dict_3rdq_allcases, hv_dict_true_med_allcases, hv_dict_true_1stq_allcases, hv_dict_true_3rdq_allcases, hv_dict_truesat_med_allcases, hv_dict_truesat_1stq_allcases, hv_dict_truesat_3rdq_allcases, nfe_array0, mark_colors, alphas, names_cases, hv_thresh):\n",
    "    print('Plotting')\n",
    "    plot_fraction_hypervolume_attained(nfe_hv_attained_dict, nfe_array0, mark_colors, names_cases, 'allcases_full', hv_thresh)\n",
    "    plot_hypervolume_stats_allcases(hv_dict_med_allcases, hv_dict_1stq_allcases, hv_dict_3rdq_allcases, nfe_array, mark_colors, alphas, names_cases, 'Hypervolume of Penalized Objectives', 'allcases_full')\n",
    "    ## Plot HVs for hv_afterjump\n",
    "    plot_hypervolume_stats_allcases(hv_dict_true_med_allcases, hv_dict_true_1stq_allcases, hv_dict_true_3rdq_allcases, nfe_array, mark_colors, alphas, names_cases, 'Hypervolume of True Objectives', 'allcases_true')\n",
    "    plot_hypervolume_stats_allcases(hv_dict_truesat_med_allcases, hv_dict_truesat_1stq_allcases, hv_dict_truesat_3rdq_allcases, nfe_array, mark_colors, alphas, names_cases, 'Hypervolume of True Objectives', 'allcases_truesat')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truss Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CASE 1 - SIMPLE E-MOEA\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "num_runs = 30 # number of runs for each case\n",
    "artery_problem = False\n",
    "sidenum = 3 # 3x3 node grid\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "\n",
    "hypervolume_computation_single_case(model_used, case_bools, artery_problem, sidenum, num_runs, 'Case1_emoea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comparing Simple E-MOEA with Int Pen - Orientation, AOS - Orientation, Bias Init - Orientation and ACH - Orientation (5000 NFE)\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "sidenum = 3 # 3x3 node grid\n",
    "cases_dict = {}\n",
    "artery_problem = False\n",
    "num_runs = 30 # number of runs for each case\n",
    "threshold_hv = 0.58\n",
    "\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case1_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # Simple E-MOEA\n",
    "case2_bools = [False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False] #  Int Pen - Orientation\n",
    "case3_bools = [False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False] #  AOS - Orientation\n",
    "case4_bools = [False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False] #  Bias Init - Orientation\n",
    "case5_bools = [False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False] #  ACH - Orientation\n",
    "\n",
    "cases_dict['case1'] = case1_bools\n",
    "cases_dict['case2'] = case2_bools\n",
    "cases_dict['case3'] = case3_bools\n",
    "cases_dict['case4'] = case4_bools\n",
    "cases_dict['case5'] = case5_bools\n",
    "\n",
    "line_colours = ['#000000','#E69F00','#56B4E9','#0072B2','#D55E00']\n",
    "casenames = ['Eps. MOEA','Int Pen - Orient','AOS - Orient','Bias Init - Orient','ACH- Orient']\n",
    "\n",
    "alpha_values = [0.5,0.5,0.5,1,1] # change based on number of cases/visibility\n",
    "\n",
    "nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, Uvals_test, Uvals_test_truesat, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mann Whitney U values\n",
    "print(\"For optimization objectives\")\n",
    "print(Uvals_test)\n",
    "print(\"\\n\")\n",
    "print(\"For true objectives of fully satisfying designs\")\n",
    "print(Uvals_test_truesat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casenames = ['Eps. MOEA.','Int Pen - Orient','AOS - Orient','Bias Init - Orient','ACH - Orient']\n",
    "plotting_all_cases(nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#print(nfe_cdf_array)\n",
    "#print(hv_dict_truesat_med_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comparing Simple E-MOEA with Int Pen - Intersection, AOS - Intersection, Bias Init - Intersection and ACH - Intersection (5000 NFE)\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "sidenum = 3 # 3x3 node grid\n",
    "cases_dict = {}\n",
    "artery_problem = False\n",
    "num_runs = 30 # number of runs for each case\n",
    "threshold_hv = 0.58\n",
    "\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case1_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # Simple E-MOEA\n",
    "case2_bools = [False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False] #  Int Pen - Intersection\n",
    "case3_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False] #  AOS - Intersection\n",
    "case4_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False] #  Bias Init - Intersection\n",
    "case5_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True] #  ACH - Intersection\n",
    "\n",
    "cases_dict['case1'] = case1_bools\n",
    "cases_dict['case2'] = case2_bools\n",
    "cases_dict['case3'] = case3_bools\n",
    "cases_dict['case4'] = case4_bools\n",
    "cases_dict['case5'] = case5_bools\n",
    "\n",
    "line_colours = ['#000000','#E69F00','#56B4E9','#0072B2','#D55E00']\n",
    "casenames = ['Eps. MOEA','Int Pen - Inters','AOS - Inters','Bias Init - Inters','ACH - Inters']\n",
    "\n",
    "alpha_values = [0.5,0.5,0.5,1,1] # change based on number of cases/visibility\n",
    "\n",
    "nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, Uvals_test, Uvals_test_truesat, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mann Whitney U values\n",
    "print(\"For optimization objectives\")\n",
    "print(Uvals_test)\n",
    "print(\"\\n\")\n",
    "print(\"For true objectives of fully satisfying designs\")\n",
    "print(Uvals_test_truesat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casenames = ['Eps. MOEA.','Int Pen - Inters','AOS - Inters','Bias Init - Inters','ACH - Inters']\n",
    "plotting_all_cases(nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#print(nfe_cdf_array)\n",
    "#print(hv_dict_truesat_med_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comparing Simple E-MOEA with AOS - all heuristics and AOS - promising heuristics\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "sidenum = 3 # 3x3 node grid\n",
    "cases_dict = {}\n",
    "artery_problem = False\n",
    "num_runs = 30 # number of runs for each case\n",
    "threshold_hv = 0.58\n",
    "\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case1_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # Simple E-MOEA\n",
    "case2_bools = [False, True, False, False, False, True, False, False, False, True, False, False, False, True, False, False] #  AOS - all heuristics\n",
    "case3_bools = [False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False] #  AOS - Orientation and Intersection\n",
    "\n",
    "cases_dict['case1'] = case1_bools\n",
    "cases_dict['case2'] = case2_bools\n",
    "cases_dict['case3'] = case3_bools\n",
    "\n",
    "line_colours = ['#000000','#E69F00','#56B4E9']\n",
    "casenames = ['Eps. MOEA','All heurs','Promising heurs']\n",
    "\n",
    "alpha_values = [0.5,0.5,0.5] # change based on number of cases/visibility\n",
    "\n",
    "#nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)\n",
    "nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, Uvals_test, Uvals_test_truesat, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mann Whitney U values\n",
    "print(\"For optimization objectives\")\n",
    "print(Uvals_test)\n",
    "print(\"\\n\")\n",
    "print(\"For true objectives of fully satisfying designs\")\n",
    "print(Uvals_test_truesat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casenames = ['Eps. MOEA.','All heurs','Promising heurs']\n",
    "plotting_all_cases(nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#print(nfe_cdf_array)\n",
    "#print(hv_dict_truesat_med_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artery Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CASE 1 - SIMPLE E-MOEA\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "num_runs = 30 # number of runs for each case\n",
    "artery_problem = True\n",
    "sidenum = 3 # 3x3 node grid\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "\n",
    "hypervolume_computation_single_case(model_used, case_bools, artery_problem, sidenum, num_runs, 'Case1_emoea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comparing Simple E-MOEA with Int Pen - Nodal Properties, AOS - Nodal Properties, Bias Init - Nodal Properties and ACH - Nodal Properties (5000 NFE)\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "sidenum = 3 # 3x3 node grid\n",
    "cases_dict = {}\n",
    "artery_problem = True\n",
    "num_runs = 30 # number of runs for each case\n",
    "threshold_hv = 0.75\n",
    "\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case1_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # Simple E-MOEA\n",
    "case2_bools = [False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False] #  Int Pen - Nodal Properties\n",
    "case3_bools = [False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False] #  AOS - Nodal Properties\n",
    "case4_bools = [False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False] #  Bias Init - Nodal Properties\n",
    "case5_bools = [False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False] #  ACH - Nodal Properties\n",
    "\n",
    "cases_dict['case1'] = case1_bools\n",
    "cases_dict['case2'] = case2_bools\n",
    "cases_dict['case3'] = case3_bools\n",
    "cases_dict['case4'] = case4_bools\n",
    "cases_dict['case5'] = case5_bools\n",
    "\n",
    "line_colours = ['#000000','#E69F00','#56B4E9','#0072B2','#D55E00']\n",
    "casenames = ['Eps. MOEA','Int Pen - NodalProp','AOS - NodalProp','Bias Init - NodalProp','ACH - NodalProp']\n",
    "\n",
    "alpha_values = [0.5,0.5,0.5,1,1] # change based on number of cases/visibility\n",
    "\n",
    "nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, Uvals_test, Uvals_test_truesat, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mann Whitney U values\n",
    "print(\"For optimization objectives\")\n",
    "print(Uvals_test)\n",
    "print(\"\\n\")\n",
    "print(\"For true objectives of fully satisfying designs\")\n",
    "print(Uvals_test_truesat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casenames = ['Eps. MOEA.','Int Pen - NodalProp','AOS - NodalProp','Bias Init - NodalProp','ACH - NodalProp']\n",
    "plotting_all_cases(nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#print(nfe_cdf_array)\n",
    "#print(hv_dict_truesat_med_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comparing Simple E-MOEA with Int Pen - Orientation, AOS - Orientation, Bias Init - Orientation and ACH - Orientation (5000 NFE)\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "sidenum = 3 # 3x3 node grid\n",
    "cases_dict = {}\n",
    "artery_problem = True\n",
    "num_runs = 30 # number of runs for each case\n",
    "threshold_hv = 0.7\n",
    "\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case1_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # Simple E-MOEA\n",
    "case2_bools = [False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False] #  Int Pen - Orientation\n",
    "case3_bools = [False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False] #  AOS - Orientation\n",
    "case4_bools = [False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False] #  Bias Init - Orientation\n",
    "case5_bools = [False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False] #  ACH - Orientation\n",
    "\n",
    "cases_dict['case1'] = case1_bools\n",
    "cases_dict['case2'] = case2_bools\n",
    "cases_dict['case3'] = case3_bools\n",
    "cases_dict['case4'] = case4_bools\n",
    "cases_dict['case5'] = case5_bools\n",
    "\n",
    "line_colours = ['#000000','#E69F00','#56B4E9','#0072B2','#D55E00']\n",
    "casenames = ['Eps. MOEA','Int Pen - Orient','AOS - Orient','Bias Init - Orient','ACH- Orient']\n",
    "\n",
    "alpha_values = [0.5,0.5,0.5,1,1] # change based on number of cases/visibility\n",
    "\n",
    "nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, Uvals_test, Uvals_test_truesat, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mann Whitney U values\n",
    "print(\"For optimization objectives\")\n",
    "print(Uvals_test)\n",
    "print(\"\\n\")\n",
    "print(\"For true objectives of fully satisfying designs\")\n",
    "print(Uvals_test_truesat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casenames = ['Eps. MOEA.','Int Pen - Orient','AOS - Orient','Bias Init - Orient','ACH - Orient']\n",
    "plotting_all_cases(nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#print(nfe_cdf_array)\n",
    "#print(hv_dict_truesat_med_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comparing Simple E-MOEA with Int Pen - Intersection, AOS - Intersection, Bias Init - Intersection and ACH - Intersection (5000 NFE)\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "sidenum = 3 # 3x3 node grid\n",
    "cases_dict = {}\n",
    "artery_problem = True\n",
    "num_runs = 30 # number of runs for each case\n",
    "threshold_hv = 0.6\n",
    "\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case1_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # Simple E-MOEA\n",
    "case2_bools = [False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False] #  Int Pen - Intersection\n",
    "case3_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False] #  AOS - Intersection\n",
    "case4_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False] #  Bias Init - Intersection\n",
    "case5_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True] #  ACH - Intersection\n",
    "\n",
    "cases_dict['case1'] = case1_bools\n",
    "cases_dict['case2'] = case2_bools\n",
    "cases_dict['case3'] = case3_bools\n",
    "cases_dict['case4'] = case4_bools\n",
    "cases_dict['case5'] = case5_bools\n",
    "\n",
    "line_colours = ['#000000','#E69F00','#56B4E9','#0072B2','#D55E00']\n",
    "casenames = ['Eps. MOEA','Int Pen - Inters','AOS - Inters','Bias Init - Inters','ACH - Inters']\n",
    "\n",
    "alpha_values = [0.5,0.5,0.5,1,1] # change based on number of cases/visibility\n",
    "\n",
    "nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, Uvals_test, Uvals_test_truesat, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mann Whitney U values\n",
    "print(\"For optimization objectives\")\n",
    "print(Uvals_test)\n",
    "print(\"\\n\")\n",
    "print(\"For true objectives of fully satisfying designs\")\n",
    "print(Uvals_test_truesat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casenames = ['Eps. MOEA.','Int Pen - Inters','AOS - Inters','Bias Init - Inters','ACH - Inters']\n",
    "plotting_all_cases(nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#print(nfe_cdf_array)\n",
    "#print(hv_dict_truesat_med_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comparing Simple E-MOEA with AOS - all heuristics and AOS - promising heuristics\n",
    "model_used = 2 # 1 = Fibre stiffness, 2 = Truss stiffness, 3 = APDL Beam\n",
    "sidenum = 3 # 3x3 node grid\n",
    "cases_dict = {}\n",
    "artery_problem = True\n",
    "num_runs = 30 # number of runs for each case\n",
    "threshold_hv = 0.58\n",
    "\n",
    "# bools = [int_pen_partcoll, AOS_partcoll, bias_init_partcoll, ACH_partcoll, int_pen_nodalprop, AOS_nodalprop, bias_init_nodalprop, ACH_nodalprop, int_pen_orient, AOS_orient, bias_init_orient, ACH_orient, int_pen_inters, AOS_inters, bias_init_inters, ACH_inters]\n",
    "case1_bools = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # Simple E-MOEA\n",
    "case2_bools = [False, True, False, False, False, True, False, False, False, True, False, False, False, True, False, False] #  AOS - all heuristics\n",
    "case3_bools = [False, False, False, False, False, True, False, False, False, True, False, False, False, True, False, False] #  AOS - NodalProp, Orientation and Intersection\n",
    "\n",
    "cases_dict['case1'] = case1_bools\n",
    "cases_dict['case2'] = case2_bools\n",
    "cases_dict['case3'] = case3_bools\n",
    "\n",
    "line_colours = ['#000000','#E69F00','#56B4E9']\n",
    "casenames = ['Eps. MOEA','All heurs','Promising heurs']\n",
    "\n",
    "alpha_values = [0.5,0.5,0.5] # change based on number of cases/visibility\n",
    "\n",
    "nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, Uvals_test, Uvals_test_truesat, nfe_array_1 = hypervolume_computation_all_cases(model_used, cases_dict, artery_problem, sidenum, num_runs, line_colours, alpha_values, casenames, threshold_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mann Whitney U values\n",
    "print(\"For optimization objectives\")\n",
    "print(Uvals_test)\n",
    "print(\"\\n\")\n",
    "print(\"For true objectives of fully satisfying designs\")\n",
    "print(Uvals_test_truesat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casenames = ['Eps. MOEA.','All heurs','Promising heurs']\n",
    "plotting_all_cases(nfe_cdf_array, hv_dict_med_cases, hv_dict_1q_cases, hv_dict_3q_cases, hv_dict_true_med_cases, hv_dict_true_1q_cases, hv_dict_true_3q_cases, hv_dict_truesat_med_cases, hv_dict_truesat_1q_cases, hv_dict_truesat_3q_cases, nfe_array_1, line_colours, alpha_values, casenames, threshold_hv)\n",
    "#print(nfe_cdf_array)\n",
    "#print(hv_dict_truesat_med_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1 = [0,1,2,3,4,5]\n",
    "x2 = [1,2,3,4,5,6]\n",
    "x3 = [2,3,4,5,6,7]\n",
    "\n",
    "#print(np.vstack((x1,x2,x3)))\n",
    "#print(np.zeros((4,2)))\n",
    "#print(np.multiply(x1,-1))\n",
    "\n",
    "#print(np.linspace(0,1,20))\n",
    "print(np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [True, True, False, True]\n",
    "print([v for i, v in enumerate(a) if b[i] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

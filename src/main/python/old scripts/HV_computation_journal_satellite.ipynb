{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygmo import hypervolume\n",
    "import csv\n",
    "import statistics\n",
    "import numpy as np\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Useful functions and parameter defintions \n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Create array of NFE values at which to compute hypervolume (assumes max function evaluations is 3000)\n",
    "n_iter_total = 50 # Total number of points in NFE array (1 more than input value to incorporate 0)\n",
    "n_iter_init = 40 # Number of initial points in NFE array separated by 50 (the rest after that are separated by 100)\n",
    "nfe_array = np.zeros(n_iter_total+1)\n",
    "for i in range(n_iter_init):\n",
    "    nfe_array[i] = 50*i\n",
    "    \n",
    "for i in range(n_iter_total - n_iter_init + 1):\n",
    "    nfe_array[n_iter_init+i] = 50*n_iter_init + 100*i\n",
    "    \n",
    "def get_true_objectives(true_obj1_array, true_obj2_array, index):\n",
    "    return true_obj1_array[index], true_obj2_array[index]\n",
    "\n",
    "def find_last_index(val,search_list):\n",
    "    if val in search_list:\n",
    "        idx = len(search_list) - search_list[::-1].index(val) - 1\n",
    "    else:\n",
    "        idx = 0\n",
    "    return idx\n",
    "\n",
    "def find_closest_index(val,search_list):\n",
    "    val_diff = np.array(search_list) - val\n",
    "    closest_index = np.argmin(np.abs(val_diff))\n",
    "    return closest_index\n",
    "\n",
    "def compute_pareto_front(population):\n",
    "    pop_size = len(population)\n",
    "    obj_num = 2\n",
    "\n",
    "    domination_counter = [0] * pop_size\n",
    "\n",
    "    for i in range(pop_size):\n",
    "        for j in range(i+1, pop_size):\n",
    "            # check each objective for dominance\n",
    "            dominate = [0] * obj_num\n",
    "            for k in range(obj_num):\n",
    "                if population[i][k] > population[j][k]:\n",
    "                    dominate[k] = 1\n",
    "                elif population[i][k] < population[j][k]:\n",
    "                    dominate[k] = -1\n",
    "            if -1 not in dominate and 1 in dominate:\n",
    "                domination_counter[i] += 1\n",
    "            elif -1 in dominate and 1 not in dominate:\n",
    "                domination_counter[j] += 1\n",
    "\n",
    "    pareto_solutions = []\n",
    "    for i in range(len(domination_counter)):\n",
    "        if domination_counter[i] == 0:\n",
    "            pareto_solutions.append(population[i])\n",
    "    return pareto_solutions\n",
    "\n",
    "def compute_hv(population):\n",
    "    array_archs = np.zeros((len(population), 2))\n",
    "    for i in range(len(population)):\n",
    "        array_archs[i] = population[i]\n",
    "    hv_object = hypervolume(array_archs)\n",
    "    hv = hv_object.compute([1.1,1.1])/1.1**2\n",
    "    return hv\n",
    "\n",
    "def get_array_element(array, index):\n",
    "    return array[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Determine csv filepath from given case type for one of the satellite problems\n",
    "def get_csv_filepath_satellite(instrdc_constrained, instrorb_constrained, interinstr_constrained, packeff_constrained, spmass_constrained, instrsyn_constrained, assigning, run_number):\n",
    "    # instrdc_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # instrorb_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # interinstr_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # packeff_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # spmass_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # instrsyn_constrained = [int_pen, AOS, bias_init, ACH] boolean array\n",
    "    # assigning = True if assigning problem data is to be read, False if partitioning problem data is to be read\n",
    "    \n",
    "    filepath = 'C:\\\\SEAK Lab\\\\SEAK Lab Github\\\\KD3M3\\\\Truss_AOS\\\\result\\\\'\n",
    "    methods = ['Int Pen','AOS','Bias Init','ACH']\n",
    "    heurs_list = ['Instrdc','Instrorb','Interinstr','Packeff','Spmass','Instrsyn']\n",
    "    heur_abbrvs_list = ['d','o','i','p','m','s']\n",
    "    heur_bools = np.vstack((instrdc_constrained, instrorb_constrained, interinstr_constrained, packeff_constrained, spmass_constrained, instrsyn_constrained))\n",
    "    aos_bools = [x[1] for x in heur_bools]\n",
    "    \n",
    "    if (any(aos_bools)):\n",
    "        filename = 'AOSMOEA_emoea_'\n",
    "    else:\n",
    "        filename = 'EpsilonMOEA_emoea_'\n",
    "        \n",
    "    if assigning_problem:\n",
    "        filepath_prob = 'Assigning Problem\\\\'\n",
    "        filename_prob = '_assign'\n",
    "    else:\n",
    "        filepath_prob = 'Partitioning Problem\\\\'\n",
    "        filename_prob = '_partition'\n",
    "        \n",
    "    filepath2 = ''\n",
    "    filename2 = ''\n",
    "    constr_count = 0\n",
    "    for i in range(len(heur_bools)):\n",
    "        constraints = methods[i] + ' - '\n",
    "        constraints_abbrv = ''\n",
    "        heur_count = 0\n",
    "        for j in range(len(heur_bools[0])):\n",
    "            if heur_bools[j][i]:\n",
    "                constraints = constraints + heurs_list[j] + '\\\\'\n",
    "                constraints_abbrv = constraints_abbrv + heurs_abbrvs_list[j]\n",
    "            else:\n",
    "                heur_count += 1\n",
    "            \n",
    "        if heur_count < len(heur_bools[0]):\n",
    "            filepath2 = filepath2 + constraints\n",
    "            filename2 = filename2 + constraints_abbrv + 'con' + str(i) + '_'\n",
    "        else:\n",
    "            constr_count += 1\n",
    "            \n",
    "    filepath_moea = ''\n",
    "    if (constr_count == len(heur_bools)):\n",
    "        filepath_moea = 'Epsilon MOEA\\\\'\n",
    "        \n",
    "    return filepath + filepath_prob + filepath2 + filepath_moea + filename + str(run_number) + filename2 + filename_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Extract Pareto Front and normalization constants data from csv file\n",
    "def extract_data_from_csv(csv_filepath, assigning, intpen_constr_heur):\n",
    "    # intpen_constr_heur = [intpen_constr_instrdc, intpen_constr_instrorb, intpen_constr_interinstr, intpen_constr_packeff, intpen_constr_spmass, intpen_constr_instrsyn] boolean array\n",
    "    with open(csv_filepath,newline='') as csvfile:\n",
    "        data = [row for row in csv.reader(csvfile)]\n",
    "                \n",
    "        num_func_evals_dat = np.zeros(len(data)-1)\n",
    "        science_pen_dat = np.zeros(len(data)-1)\n",
    "        cost_pen_dat = np.zeros(len(data)-1)\n",
    "        science_dat = np.zeros(len(data)-1)\n",
    "        cost_dat = np.zeros(len(data)-1)\n",
    "        \n",
    "        instrdc_scores_dat = np.zeros(len(data)-1)\n",
    "        instrorb_scores_dat = np.zeros(len(data)-1)\n",
    "        interinstr_scores_dat = np.zeros(len(data)-1)\n",
    "        packeff_scores_dat = np.zeros(len(data)-1)\n",
    "        spmass_scores_dat = np.zeros(len(data)-1)\n",
    "        instrsyn_scores_dat = np.zeros(len(data)-1)\n",
    "        \n",
    "        valid_count = 0\n",
    "        for x in range(len(data)-1):\n",
    "            data_float = list(map(float,data[x+1][1:]))\n",
    "            if (any(np.isnan(np.array(data_float))) or any(np.isinf(np.array(data_float)))):\n",
    "                continue\n",
    "            \n",
    "            num_func_evals_dat[valid_count] = int(data[x+1][1])\n",
    "            science_pen_dat[valid_count] = int(data[x+1][2])\n",
    "            cost_pen_dat[valid_count] = int(data[x+1][3])\n",
    "            science_dat[valid_count] = float(data[x+1][4])\n",
    "            cost_dat[valid_count] = float(data[x+1][5])\n",
    "            \n",
    "            instrdc_scores_dat[valid_count] = float(data[x+1][6])\n",
    "            instrorb_scores_dat[valid_count] = float(data[x+1][7])\n",
    "            interinstr_scores_dat[valid_count] = float(data[x+1][8])\n",
    "            packeff_scores_dat[valid_count] = float(data[x+1][9])\n",
    "            spmass_scores_dat[valid_count] = float(data[x+1][10])\n",
    "            instrsyn_scores_dat[valid_count] = float(data[x+1][11])\n",
    "    \n",
    "            valid_count += 1\n",
    "            \n",
    "    #archs = archs_dat[:valid_count]\n",
    "    num_func_evals = num_func_evals_dat[:valid_count]\n",
    "    science_pen = science_pen_dat[:valid_count]\n",
    "    cost_pen = cost_pen_dat[:valid_count]\n",
    "    science = science_dat[:valid_count]\n",
    "    cost = cost_dat[:valid_count]\n",
    "    \n",
    "    instrdc_scores = instrdc_scores_dat[:valid_count]\n",
    "    instrorb_scores = instrorb_scores_dat[:valid_count]\n",
    "    interinstr_scores = interinstr_scores_dat[:valid_count]\n",
    "    packeff_scores = packeff_scores_dat[:valid_count]\n",
    "    spmass_scores = spmass_scores_dat[:valid_count]\n",
    "    instrsyn_scores = instrsyn_scores_dat[:valid_count]\n",
    "            \n",
    "    #print('science')\n",
    "    #print(science)\n",
    "    #print('\\n')\n",
    "    #print('cost')\n",
    "    #print(cost)\n",
    "    #print('\\n')\n",
    "    \n",
    "    ## Sort num_fun_evals (and objectives and heuristic scores) in ascending order\n",
    "    n_func_evals = num_func_evals\n",
    "    sort_indices = np.argsort(n_func_evals)\n",
    "    science_pen_sorted = list(science_pen[sort_indices])\n",
    "    cost_pen_sorted = list(cost_pen[sort_indices])\n",
    "    cost_sorted = list(cost[sort_indices])\n",
    "    science_sorted = list(science[sort_indices])\n",
    "    cost_sorted = list(cost[sort_indices])\n",
    "    \n",
    "    instrdc_scores_sorted = list(instrdc_scores[sort_indices])\n",
    "    instrorb_scores_sorted = list(instrorb_scores[sort_indices])\n",
    "    interinstr_scores_sorted = list(interinstr_scores[sort_indices])\n",
    "    packeff_scores_sorted = list(packeff_scores[sort_indices])\n",
    "    spmass_scores_sorted = list(spamss_scores[sort_indices])\n",
    "    instrsyn_scores_sorted = list(instrsyn_scores[sort_indices])\n",
    "    \n",
    "    #archs_sorted = []\n",
    "    #for i in range(len(sort_indices)):\n",
    "        #archs_sorted.append(archs[sort_indices[i]])\n",
    "    \n",
    "    heur_scores_sorted = np.vstack((instrdc_scores_sorted, instrorb_scores_sorted, interinstr_scores_sorted, packeff_scores_sorted, spmass_scores_sorted, instrsyn_scores_sorted))\n",
    "    \n",
    "    ## Compute only constraint penalized objectives (used for the interior penalty cases)\n",
    "    heur_obj_weight = 1 # weightage of heuristic penalties wrt objectives\n",
    "    heur_weights = [[1, 1, 1, 1, 1, 1], [1000, 1000, 1000, 1000, 1000, 1000]] \n",
    "    # Row 1 - heur_weights for science, Row 2 - heur_weights for cost\n",
    "    # heur_weights in each row - [instrdc, instrorb, interinstr, packeff, spmass, instrsyn]\n",
    "    \n",
    "    heur_pen = np.zeros((len(instrdc_scores_sorted),2))\n",
    "    if (any(intpen_constr_heur)):\n",
    "        heur_index_array = np.arange(len(intpen_constr_heur))\n",
    "        heur_index_used = [v for i, v in enumerate(heur_index_array) if intpen_constr_heur[i] == True]\n",
    "     \n",
    "        for idx in heur_index_used:\n",
    "            heur_scores_idx = heur_scores_sorted[idx]\n",
    "            heur_pen_science_idx = [heur_weights[0][idx]*x for x in heur_scores_idx]\n",
    "            heur_pen_cost_idx = [heur_weights[1][idx]*x for x in heur_scores_idx]\n",
    "            heur_pen[0] = np.add(heur_pen[0], heur_pen_science_idx/len(heur_index_used))\n",
    "            heur_pen[1] = np.add(heur_pen[1], heur_pen_cost_idx/len(heur_index_used))\n",
    "            \n",
    "    weighted_heur_science_pen = [k*heur_obj_weight for k in heur_pen[0]]\n",
    "    weighted_heur_cost_pen = [k*heur_obj_weight for k in heur_pen[1]]\n",
    "    \n",
    "    science_constr_sorted = list(np.add(science_pen_sorted,weighted_heur_science_pen))\n",
    "    cost_constr_sorted = list(np.add(cost_pen_sorted,weighted_heur_cost_pen))\n",
    "    \n",
    "    ## Determine normalizing objective scores and compute pareto fronts for penalized and true objectives as well as for true objectives of only feasible designs \n",
    "    nfe_list_sorted = list(n_func_evals[sort_indices])\n",
    "    \n",
    "    #max_func_evals = nfe_list_sorted[-1]\n",
    "    max_func_evals = 5000 # some runs for some cases run upto 3001 evaluations, which causes hv array length issues\n",
    "\n",
    "    pareto_front_dict = {}\n",
    "    #pareto_front_instrdc_dict = {}\n",
    "    #pareto_front_instrorb_dict = {}\n",
    "    #pareto_front_interinstr_dict = {}\n",
    "    #pareto_front_packeff_dict = {}\n",
    "    #pareto_front_spmass_dict = {}\n",
    "    #pareto_front_instrsyn_dict = {}\n",
    "    #pareto_front_archs_dict = {}\n",
    "    pareto_front_true_dict = {}\n",
    "\n",
    "    pf_normalize_max_obj1 = []\n",
    "    pf_normalize_min_obj1 = []\n",
    "    pf_normalize_max_obj2 = []\n",
    "    pf_normalize_min_obj2 = []\n",
    "    pf_true_normalize_max_obj1 = []\n",
    "    pf_true_normalize_min_obj1 = []\n",
    "    pf_true_normalize_max_obj2 = []\n",
    "    pf_true_normalize_min_obj2 = []\n",
    "    \n",
    "    count = 0\n",
    "    pop_size = int(find_last_index(0, nfe_list_sorted))\n",
    "    nfe_jump_recorded = False\n",
    "\n",
    "    for nfe_val in nfe_array:\n",
    "        #print('iter = ' + str(i))\n",
    "    \n",
    "        if (nfe_list_sorted[0] == 0):\n",
    "            if (nfe_val <= 100): # population size set at 100 in java code, but maybe different here due to NaNs\n",
    "                nfe_index_current = pop_size+1\n",
    "            else:\n",
    "                nfe_index_current = find_closest_index(nfe_val, nfe_list_sorted)\n",
    "        else:\n",
    "            if (nfe_val <= nfe_list_sorted[0]):\n",
    "                nfe_index_current = 1\n",
    "            else:\n",
    "                nfe_index_current = find_closest_index(nfe_val, nfe_list_sorted)\n",
    "        \n",
    "        nfe_array_current = nfe_list_sorted[:nfe_index_current]\n",
    "        current_population = []\n",
    "        for j in range(len(nfe_array_current)):\n",
    "            current_population.append([science_constr_sorted[j], cost_constr_sorted[j]])\n",
    "            \n",
    "        #if (\"AOS - Orient\\\\\" in csv_filepath) and (\"emoea_16\" in csv_filepath):\n",
    "            #set_trace()\n",
    "        \n",
    "        current_pareto_front_all = compute_pareto_front(current_population)\n",
    "        #current_pareto_front = list(set(current_pareto_front_all))\n",
    "        current_pareto_front = np.unique(current_pareto_front_all, axis=0)\n",
    "    \n",
    "        #current_pareto_instrdc_scores = []\n",
    "        #current_pareto_instrorb_scores = []\n",
    "        #current_pareto_interinstr_scores = []\n",
    "        #current_pareto_packeff_scores = []\n",
    "        #current_pareto_spmass_scores = []\n",
    "        #current_pareto_instrsyn_scores = []\n",
    "        #current_pareto_archs = []\n",
    "        current_pareto_trueobjs = []\n",
    "        for pareto_arch in current_pareto_front:\n",
    "            arch_index = science_constr_sorted.index(pareto_arch[0])\n",
    "            #arch_instrdc_score = get_array_element(instrdc_scores_sorted, arch_index)\n",
    "            #arch_instrorb_score = get_array_element(instrorb_scores_sorted, arch_index)\n",
    "            #arch_interinstr_score = get_array_element(interinstr_scores_sorted, arch_index)\n",
    "            #arch_packeff_score = get_array_element(packeff_scores_sorted, arch_index)\n",
    "            #arch_spmass_score = get_array_element(spmass_scores_sorted, arch_index)\n",
    "            #arch_instrsyn_score = get_array_element(instsyn_scores_sorted, arch_index)\n",
    "            \n",
    "            #current_pareto_instrdc_scores.append(arch_instrdc_score)\n",
    "            #current_pareto_instrorb_scores.append(arch_instrorb_score)\n",
    "            #current_pareto_interinstr_scores.append(arch_interinstr_score)\n",
    "            #current_pareto_packeff_scores.append(arch_packeff_score)\n",
    "            #current_pareto_spmass_scores.append(arch_spmass_score)\n",
    "            #current_pareto_instrsyn_scores.append(arch_instrsyn_score)\n",
    "            #current_pareto_archs.append(get_array_element(archs_sorted, arch_index))\n",
    "            \n",
    "            science_arch, cost_arch = get_true_objectives(science_sorted, cost_sorted, arch_index)\n",
    "        \n",
    "            #set_trace()\n",
    "            \n",
    "            current_pareto_trueobjs.append([science_arch, cost_arch])\n",
    "                   \n",
    "        pareto_front_dict[nfe_val] = current_pareto_front\n",
    "        #pareto_front_instrdc_dict[nfe_val] = current_pareto_instrdc_scores\n",
    "        #pareto_front_instrorb_dict[nfe_val] = current_pareto_instrorb_scores\n",
    "        #pareto_front_interinstr_dict[nfe_val] = current_pareto_interinstr_scores\n",
    "        #pareto_front_packeff_dict[nfe_val] = current_pareto_packeff_scores\n",
    "        #pareto_front_spmass_dict[nfe_val] = current_pareto_spmass_scores\n",
    "        #pareto_front_instrsyn_dict[nfe_val] = current_pareto_instrsyn_scores\n",
    "        #pareto_front_archs_dict[nfe_val] = current_pareto_archs\n",
    "        pareto_front_true_dict[nfe_val] = current_pareto_trueobjs\n",
    "        \n",
    "        pf_nfeval_obj1 = [row[0] for row in current_pareto_front]\n",
    "        pf_nfeval_obj2 = [row[1] for row in current_pareto_front]\n",
    "        \n",
    "        pf_true_nfeval_obj1 = [row[0] for row in current_pareto_trueobjs]\n",
    "        pf_true_nfeval_obj2 = [row[1] for row in current_pareto_trueobjs]\n",
    "        \n",
    "        pf_normalize_max_obj1.append(np.max(pf_nfeval_obj1))\n",
    "        pf_normalize_min_obj1.append(np.min(pf_nfeval_obj1))\n",
    "        pf_normalize_max_obj2.append(np.max(pf_nfeval_obj2))\n",
    "        pf_normalize_min_obj2.append(np.min(pf_nfeval_obj2))\n",
    "        \n",
    "        pf_true_normalize_max_obj1.append(np.max(pf_true_nfeval_obj1))\n",
    "        pf_true_normalize_min_obj1.append(np.min(pf_true_nfeval_obj1))\n",
    "        pf_true_normalize_max_obj2.append(np.max(pf_true_nfeval_obj2))\n",
    "        pf_true_normalize_min_obj2.append(np.min(pf_true_nfeval_obj2))\n",
    "\n",
    "    ### Computing obj_normalize_fullrun, obj_normalize_afterjump and obj_normalized_true_fullrun using the entire run \n",
    "    #obj_normalize_max_fullrun = [np.max(pen_obj1_constr_sorted), np.max(pen_obj2_constr_sorted)]\n",
    "    #obj_normalize_min_fullrun = [np.min(pen_obj1_constr_sorted), np.min(pen_obj2_constr_sorted)]\n",
    "    \n",
    "    #obj_true_normalize_max_fullrun = [np.max(true_obj1_sorted), np.max(true_obj2_sorted)]\n",
    "    #obj_true_normalize_min_fullrun = [np.min(true_obj1_sorted), np.min(true_obj2_sorted)]\n",
    "\n",
    "    #obj_normalize_fullrun = [obj_normalize_min_fullrun, obj_normalize_max_fullrun]\n",
    "    \n",
    "    #obj_normalize_true_fullrun = [obj_true_normalize_min_fullrun, obj_true_normalize_max_fullrun]\n",
    "    \n",
    "    ### Computing obj_normalize_fullrun using the pareto fronts\n",
    "    obj_normalize_max_fullrun = [np.max(pf_normalize_max_obj1), np.max(pf_normalize_max_obj2)]\n",
    "    obj_normalize_min_fullrun = [np.min(pf_normalize_min_obj1), np.min(pf_normalize_min_obj2)]  \n",
    "    \n",
    "    obj_true_normalize_max_fullrun = [np.max(pf_true_normalize_max_obj1), np.max(pf_true_normalize_max_obj2)]\n",
    "    obj_true_normalize_min_fullrun = [np.min(pf_true_normalize_min_obj1), np.min(pf_true_normalize_min_obj2)]\n",
    "    \n",
    "    obj_normalize_fullrun = [obj_normalize_min_fullrun, obj_normalize_max_fullrun]\n",
    "    \n",
    "    obj_normalize_true_fullrun = [obj_true_normalize_min_fullrun, obj_true_normalize_max_fullrun]\n",
    "    \n",
    "    return pareto_front_dict, pareto_front_true_dict, obj_normalize_fullrun, obj_normalize_true_fullrun, max_func_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute overall normalization objectives for single case study/all compared case studies (from the complete runs)\n",
    "def compute_overall_norm_objs(objs_normalization_full, objs_normalization_true):\n",
    "    # Each input is a dictionary with key as the case study/run string and value as the corresponding 2D array\n",
    "    \n",
    "    obj1_max_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj1_min_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj2_max_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj2_min_full_allcases = np.zeros(len(objs_normalization_full))\n",
    "    obj1_max_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    obj1_min_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    obj2_max_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    obj2_min_true_allcases = np.zeros(len(objs_normalization_true))\n",
    "    \n",
    "    i = 0\n",
    "    for key in objs_normalization_full:\n",
    "        current_objs_norm_full = objs_normalization_full[key]\n",
    "        \n",
    "        obj1_max_full_allcases[i] = current_objs_norm_full[1][0]\n",
    "        obj2_max_full_allcases[i] = current_objs_norm_full[1][1]\n",
    "        obj1_min_full_allcases[i] = current_objs_norm_full[0][0]\n",
    "        obj2_min_full_allcases[i] = current_objs_norm_full[0][1]\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    for key3 in objs_normalization_true:\n",
    "        current_objs_norm_true = objs_normalization_true[key3]\n",
    "        \n",
    "        obj1_max_true_allcases[i] = current_objs_norm_true[1][0]\n",
    "        obj2_max_true_allcases[i] = current_objs_norm_true[1][1]\n",
    "        obj1_min_true_allcases[i] = current_objs_norm_true[0][0]\n",
    "        obj2_min_true_allcases[i] = current_objs_norm_true[0][1]\n",
    "        i += 1\n",
    "        \n",
    "    obj1_min_full_overall = np.min(obj1_min_full_allcases)\n",
    "    obj2_min_full_overall = np.min(obj2_min_full_allcases)\n",
    "    obj1_max_full_overall = np.max(obj1_max_full_allcases)\n",
    "    obj2_max_full_overall = np.max(obj2_max_full_allcases)\n",
    "    \n",
    "    obj1_min_true_overall = np.min(obj1_min_true_allcases)\n",
    "    obj2_min_true_overall = np.min(obj2_min_true_allcases)\n",
    "    obj1_max_true_overall = np.max(obj1_max_true_allcases)\n",
    "    obj2_max_true_overall = np.max(obj2_max_true_allcases)\n",
    "            \n",
    "    obj_norm_full_overall = [[obj1_min_full_overall, obj2_min_full_overall], [obj1_max_full_overall, obj2_max_full_overall]]\n",
    "    obj_norm_true_overall = [[obj1_min_true_overall, obj2_min_true_overall], [obj1_max_true_overall, obj2_max_true_overall]]    \n",
    "     \n",
    "    return obj_norm_full_overall, obj_norm_true_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute hypervolume arrays from copmuted pareto fronts and normalization constants\n",
    "def compute_hv_arrays_from_csv_data(pf_dict, pf_true_dict, obj_norm_full, obj_norm_true_full, max_fun_evals):\n",
    "    obj_norm_min_full = obj_norm_full[0]\n",
    "    obj_norm_max_full = obj_norm_full[1]\n",
    "    obj_norm_true_min_full = obj_norm_true_full[0]\n",
    "    obj_norm_true_max_full = obj_norm_true_full[1]\n",
    "\n",
    "    ## Normalize the pareto front objectives and compute the hypervolume\n",
    "    hypervol_full_dict = []\n",
    "    hypervol_true_full_dict = []\n",
    "\n",
    "    for nfe_val in nfe_array:\n",
    "        #print('iter = ' + str(nfe_val))\n",
    "    \n",
    "        current_pareto_front = pf_dict[nfe_val]\n",
    "        current_true_pareto_front = pf_true_dict[nfe_val]\n",
    "        current_pf_normalized = []\n",
    "        current_pf_true_normalized = []\n",
    "        for pareto_design in current_pareto_front:\n",
    "            obj1_normalized = (pareto_design[0] - obj_norm_min_full[0])/(obj_norm_max_full[0] - obj_norm_min_full[0])\n",
    "            obj2_normalized = (pareto_design[1] - obj_norm_min_full[1])/(obj_norm_max_full[1] - obj_norm_min_full[1])\n",
    "            current_pf_normalized.append([obj1_normalized, obj2_normalized])\n",
    "                    \n",
    "        for pareto_design_true in current_true_pareto_front:\n",
    "            obj1_true_normalized = (obj_norm_true_max_full[0] - pareto_design_true[0])/(obj_norm_true_max_full[0] - obj_norm_true_min_full[0])\n",
    "            obj2_true_normalized = (pareto_design_true[1] - obj_norm_true_min_full[1])/(obj_norm_true_max_full[1] - obj_norm_true_min_full[1])\n",
    "            current_pf_true_normalized.append([obj1_true_normalized, obj2_true_normalized])\n",
    "            \n",
    "        current_hv = compute_hv(current_pf_normalized)\n",
    "        hypervol_full_dict.append([nfe_val, current_hv])\n",
    "        \n",
    "        current_hv_true = compute_hv(current_pf_true_normalized)\n",
    "        hypervol_true_full_dict.append([nfe_val, current_hv_true])\n",
    "        \n",
    "    return hypervol_full_dict, hypervol_true_full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute array of NFE values for reaching threshold hypervolume for different runs of a particular case\n",
    "def compute_nfe_hypervolume_attained(hv_dict):\n",
    "    hv_threshold = 0.75 # Threshold HV value to reach, user parameter\n",
    "    n_runs = len(hv_dict)\n",
    "    nfe_hv_attained = []\n",
    "    for key in hv_dict:\n",
    "        hv_array_run = hv_dict[key]\n",
    "        nfe_array_run = [hv_array[0] for hv_array in hv_array_run]\n",
    "        hv_val_array = [hv_array[1] for hv_array in hv_array_run]\n",
    "        nfe_hv_attained_run = nfe_array_run[-1] + 100\n",
    "        for i in range(len(hv_val_array)):\n",
    "            if (hv_val_array[i] >= hv_threshold):\n",
    "                nfe_hv_attained_run = nfe_array_run[i]\n",
    "                break\n",
    "                \n",
    "        #hv_val_diff = [np.abs(x - hv_threshold) for x in hv_val_array]\n",
    "        #index = np.argmin(hv_val_diff)\n",
    "        nfe_hv_attained.append(nfe_hv_attained_run)\n",
    "        \n",
    "    return nfe_hv_attained\n",
    "    \n",
    "### Plot fraction of runs attaining threshold hypervolume vs NFE\n",
    "def plot_fraction_hypervolume_attained(nfe_hv_attained_dict, nfe_array, colour_array, casename_array, savefig_name):\n",
    "    fig1 = plt.figure(1)\n",
    "    n_cases = len(nfe_hv_attained_dict)\n",
    "    case_idx = 0\n",
    "    for case_key in nfe_hv_attained_dict:\n",
    "        nfe_hv_attained_case = nfe_hv_attained_dict[case_key]\n",
    "        n_runs = len(nfe_hv_attained_case)\n",
    "        frac_runs_hv_attained = np.zeros(len(nfe_array))\n",
    "        for i in range(len(nfe_array)):\n",
    "            idx_runs_hv_attained = [idx for idx, val in enumerate(nfe_hv_attained_case) if val <= nfe_array[i]]\n",
    "            frac_runs_hv_attained[i] = len(idx_runs_hv_attained)/n_runs\n",
    "            \n",
    "        plt.plot(nfe_array, frac_runs_hv_attained, '-', color=colour_array[case_idx], label=casename_array[case_idx])\n",
    "        case_idx += 1\n",
    "    \n",
    "    plt.xlabel('Number of Function Evaluations',fontsize=14)\n",
    "    plt.ylabel('Fraction of runs HV $\\geq$ 0.75',fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.20), ncol=3, borderaxespad=0 ,prop={\"size\":12})\n",
    "    plt.show()\n",
    "    fig1.savefig('frac_hv_attained_' + savefig_name + '.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hypervolume_stats(hypervols_dict):\n",
    "    hv_dict_keys = list(hypervols_dict.keys())\n",
    "    hv_dict_0 = hypervols_dict[hv_dict_keys[0]]\n",
    "    nfe_array_0 = [hv_array[0] for hv_array in hv_dict_0]\n",
    "    n_datapoints = len(nfe_array_0)\n",
    "    hypervol_median = np.zeros(n_datapoints)\n",
    "    hypervol_1q = np.zeros(n_datapoints)\n",
    "    hypervol_3q = np.zeros(n_datapoints)\n",
    "    for i in range(n_datapoints):\n",
    "        hypervol_vals = []\n",
    "        for key in hypervols_dict:\n",
    "            hv_dict_j = hypervols_dict[key]\n",
    "            hv_current_array = [hv_array[1] for hv_array in hv_dict_j]\n",
    "            hypervol_vals.append(hv_current_array[i])\n",
    "        hypervol_median[i] = statistics.median(hypervol_vals)\n",
    "        #hypervol_median[i] = statistics.mean(hypervol_vals)\n",
    "        hypervol_1q[i] = np.percentile(hypervol_vals, 25)\n",
    "        #hypervol_1q[i] = hypervol_median[i] - statistics.stdev(hypervol_vals)\n",
    "        hypervol_3q[i] = np.percentile(hypervol_vals, 75)\n",
    "        #hypervol_3q[i] = hypervol_median[i] + statistics.stdev(hypervol_vals)\n",
    "        \n",
    "    return hypervol_median, hypervol_1q, hypervol_3q, nfe_array_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hypervolume_stats(hv_median_case, hv_1q_case, hv_3q_case, nfe_array, savefig_name):\n",
    "    fig1 = plt.figure(1)\n",
    "    plt.plot(nfe_array,hv_median_case, 'b-', label='Median')\n",
    "    plt.plot(nfe_array,hv_1q_case, 'r-', label='1st Quartile')\n",
    "    plt.plot(nfe_array,hv_3q_case, 'g-', label='3rd Quartile')\n",
    "    plt.xlabel('Number of Function Evaluations')\n",
    "    plt.ylabel('Hypervolume')\n",
    "    plt.title('Averaged Hypervolume vs NFE')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    #fig1.savefig('HV_plot_averaged_' + savefig_name + '.png')\n",
    "    \n",
    "def plot_hypervolume_stats_allcases(hv_median_dict, hv_1q_dict, hv_3q_dict, nfe_array, colour_array, alpha_array, casename_array, plot_title, savefig_name):\n",
    "    fig1 = plt.figure(1)\n",
    "    number_cases = len(hv_median_dict)\n",
    "    #print('n_cases')\n",
    "    #print(number_cases)\n",
    "    for i in range(number_cases):\n",
    "        #print(print(marker_array[i]+'*'))\n",
    "        plt.plot(nfe_array, hv_median_dict['case'+str(i)], '-', color=colour_array[i], label=casename_array[i])\n",
    "        #plt.fill_between(nfe_array, hv_1q_dict['case'+str(i)], hv_3q_dict['case'+str(i)], color=colour_array[i], alpha=alpha_array[i])\n",
    "        \n",
    "        plt.plot(nfe_array, hv_1q_dict['case'+str(i)], '--', color=colour_array[i])#, label=casename_array[i]+' 1st Quartile')\n",
    "        plt.plot(nfe_array, hv_3q_dict['case'+str(i)], '--', color=colour_array[i])#, label=casename_array[i]+' 3rd Quartile')\n",
    "    plt.xlabel('Number of Function Evaluations',fontsize=14)\n",
    "    plt.ylabel('Hypervolume',fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    #plt.title(plot_title)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5,1.20), ncol=3, borderaxespad=0, prop={\"size\":12})\n",
    "    plt.show()\n",
    "    fig1.savefig('HV_plot_averaged_' + savefig_name + '.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define functions to compute and plot hypervolume for single case and all cases\n",
    "def hypervolume_computation_single_case(case_booleans, prob_assigning, run_nums, case_name):\n",
    "    ## Computing the pareto fronts and normalization objectives for each run\n",
    "    obj_norm_allruns = {}\n",
    "    obj_norm_true_allruns = {}\n",
    "    pf_allruns = {}\n",
    "    pf_true_allruns = {}\n",
    "    max_f_evals_allruns = np.zeros(run_nums)\n",
    "    for i in range(run_nums):\n",
    "        print('Computing Pareto Fronts for run ' + str(i))\n",
    "        current_csvpath = get_csv_filepath_satellite(case_booleans[:4], case_booleans[4:8], case_booleans[8:12], case_booleans[12:16], case_booleans[16:20], case_booleans[20:24], prob_assigning, i)\n",
    "        heur_intpen_constr = [case_booleans[0], case_booleans[4], case_booleans[8], case_booleans[12]]\n",
    "        pf_dict_i, pf_true_dict_i, obj_norm_full_i, obj_norm_true_i, max_fun_evals_i = extract_data_from_csv(current_csvpath, prob_assigning, heur_intpen_constr)\n",
    "        pf_allruns['run'+str(i)] = pf_dict_i\n",
    "        pf_true_allruns['run'+str(i)] = pf_true_dict_i\n",
    "        obj_norm_allruns['run'+str(i)] = obj_norm_full_i\n",
    "        obj_norm_true_allruns['run'+str(i)] = obj_norm_true_i\n",
    "        max_f_evals_allruns[i] = max_fun_evals_i\n",
    "    \n",
    "    #print('pf_allruns')\n",
    "    #print(pf_allruns)\n",
    "    #print('\\n')\n",
    "    #print('pf_true_allruns')\n",
    "    #print(pf_true_allruns)\n",
    "    #print('\\n')\n",
    "    ## Use computed normalization objectives and find the overall normalization objectives across all runs\n",
    "    print('Computing overall normalization constants')\n",
    "    norm_objs_full_overall, norm_objs_true_overall = compute_overall_norm_objs(obj_norm_allruns, obj_norm_true_allruns)\n",
    "    #print('norm_objs_full_overall')\n",
    "    #print(norm_objs_full_overall)\n",
    "    #print('\\n')\n",
    "    #print('norm_objs_true_overall')\n",
    "    #print(norm_objs_true_overall)\n",
    "    #print('\\n')\n",
    "    \n",
    "    ## Compute Hypervolume values for each run\n",
    "    hv_dict_allruns = {}\n",
    "    hv_dict_true_allruns = {}\n",
    "    for j in range(run_nums):\n",
    "        print('Computing hypervolume values for run ' + str(j))\n",
    "        hv_dict_j, hv_dict_true_j = compute_hv_arrays_from_csv_data(pf_allruns['run'+str(j)], pf_true_allruns['run'+str(j)], norm_objs_full_overall, norm_objs_true_overall, max_f_evals_allruns[j])\n",
    "        hv_dict_allruns['run'+str(j)] = hv_dict_j\n",
    "        hv_dict_true_allruns['run'+str(j)] = hv_dict_true_j\n",
    "        \n",
    "    #print('hv_dict_allruns')\n",
    "    #print(hv_dict_allruns)\n",
    "    #print('hv_dict_true_allruns')\n",
    "    #print(hv_dict_true_allruns)\n",
    "        \n",
    "    ## Plotting\n",
    "    print('Plotting')\n",
    "    hv_median_all, hv_1q_all, hv_3q_all, nfe_array = compute_hypervolume_stats(hv_dict_allruns)\n",
    "    plot_hypervolume_stats(hv_median_all, hv_1q_all, hv_3q_all, nfe_array, case_name+'_full')\n",
    "\n",
    "    ## Plot HVs for hv_afterjump\n",
    "\n",
    "    ## Plot HVs for true objectives\n",
    "    hv_true_median_all, hv_true_1q_all, hv_true_3q_all, nfe_array_true = compute_hypervolume_stats(hv_dict_true_allruns)\n",
    "    plot_hypervolume_stats(hv_true_median_all, hv_true_1q_all, hv_true_3q_all, nfe_array_true, case_name+'_true')\n",
    "    \n",
    "    \n",
    "def hypervolume_computation_all_cases(choice_model, case_bools_dict, prob_assigning, run_nums, marker_colours, alpha_vals, case_names):\n",
    "    num_cases = len(case_bools_dict) # number of cases to compare \n",
    "\n",
    "    ## Computing the pareto fronts and normalization objectives for each run in each case\n",
    "    pf_allcases = {}\n",
    "    pf_true_allcases = {}\n",
    "    obj_norm_allcasesandruns = {}\n",
    "    obj_norm_true_allcasesandruns = {}\n",
    "    max_f_evals_allcases = {}\n",
    "    for i in range(num_cases):\n",
    "        print('Computing Pareto Fronts for runs in Case '+str(i))\n",
    "        current_case_bools = case_bools_dict['case'+str(i+1)]\n",
    "        #set_trace()\n",
    "        pf_allruns_i = {}\n",
    "        pf_true_allruns_i = {}\n",
    "        max_f_evals_allruns = np.zeros(run_nums)\n",
    "        for j in range(run_nums):\n",
    "            print('Run '+str(j))\n",
    "            current_csvpath = get_csv_filepath_satellite(current_case_bools[:4], current_case_bools[4:8], current_case_bools[8:12], current_case_bools[12:16], current_case_bools[16:20], current_case_bools[20:24], prob_assigning, j)\n",
    "            #set_trace()\n",
    "            heur_intpen_constr = [current_case_bools[0], current_case_bools[4], current_case_bools[8], current_case_bools[12]]\n",
    "            pf_dict_j, pf_true_dict_j, obj_norm_full_j, obj_norm_true_j, max_fun_evals_j = extract_data_from_csv(current_csvpath, prob_assigning, heur_intpen_constr)\n",
    "            pf_allruns_i['run'+str(j)] = pf_dict_j\n",
    "            pf_true_allruns_i['run'+str(j)] = pf_true_dict_j\n",
    "            obj_norm_allcasesandruns['case'+str(i+1)+'run'+str(j)] = obj_norm_full_j\n",
    "            obj_norm_true_allcasesandruns['case'+str(i+1)+'run'+str(j)] = obj_norm_true_j\n",
    "            max_f_evals_allruns[j] = max_fun_evals_j\n",
    "        pf_allcases['case'+str(i+1)] = pf_allruns_i\n",
    "        pf_true_allcases['case'+str(i+1)] = pf_true_allruns_i\n",
    "        max_f_evals_allcases['case'+str(i+1)] = max_f_evals_allruns\n",
    "    \n",
    "    ## Use computed normalization objectives and find the overall normalization objectives across all runs and cases\n",
    "    print('Computing overall normalization constants')\n",
    "    norm_objs_full_overall, norm_objs_true_overall = compute_overall_norm_objs(obj_norm_allcasesandruns, obj_norm_true_allcasesandruns)\n",
    "    \n",
    "    #set_trace()\n",
    "    \n",
    "    ## Compute Hypervolume values for each run in each case\n",
    "    hv_dict_median_allcases = {}\n",
    "    hv_dict_1q_allcases = {}\n",
    "    hv_dict_3q_allcases = {}\n",
    "    hv_dict_true_median_allcases = {}\n",
    "    hv_dict_true_1q_allcases = {}\n",
    "    hv_dict_true_3q_allcases = {}\n",
    "    nfe_array_hv_attained_dict = {}\n",
    "    for i in range(num_cases):\n",
    "        print('Computing hypervolume values for runs in Case '+str(i))\n",
    "        pfs_case_i = pf_allcases['case'+str(i+1)]\n",
    "        pfs_true_case_i = pf_true_allcases['case'+str(i+1)]\n",
    "        max_func_evals_i = max_f_evals_allcases['case'+str(i+1)]\n",
    "        hv_dict_allruns = {}\n",
    "        hv_dict_true_allruns = {}\n",
    "        for j in range(run_nums):\n",
    "            print('Run '+str(j))\n",
    "            hv_dict_j, hv_dict_true_j = compute_hv_arrays_from_csv_data(pfs_case_i['run'+str(j)], pfs_true_case_i['run'+str(j)], norm_objs_full_overall, norm_objs_true_overall, max_func_evals_i[j])\n",
    "            hv_dict_allruns['run'+str(j)] = hv_dict_j\n",
    "            hv_dict_true_allruns['run'+str(j)] = hv_dict_true_j\n",
    "            \n",
    "        print('Computing array of NFE for attaining threshold hypervolume')\n",
    "        nfe_hv_attained_case = compute_nfe_hypervolume_attained(hv_dict_allruns)\n",
    "        nfe_array_hv_attained_dict['case'+str(i)] = nfe_hv_attained_case\n",
    "                \n",
    "        print('Computing hypervolume stats')\n",
    "        hv_med_i, hv_1q_i, hv_3q_i, nfe_array_i = compute_hypervolume_stats(hv_dict_allruns)\n",
    "        #hv_med_aj_i, hv_1q_aj_i, hv_3q_aj_i, nfe_array_aj_i = compute_hypervolume_stats(hv_dict_aj_allruns)\n",
    "        hv_med_true_i, hv_1q_true_i, hv_3q_true_i, nfe_array_true_i = compute_hypervolume_stats(hv_dict_true_allruns)\n",
    "                \n",
    "        hv_dict_median_allcases['case'+str(i)] = hv_med_i\n",
    "        hv_dict_1q_allcases['case'+str(i)] = hv_1q_i\n",
    "        hv_dict_3q_allcases['case'+str(i)] = hv_3q_i\n",
    "        hv_dict_true_median_allcases['case'+str(i)] = hv_med_true_i\n",
    "        hv_dict_true_1q_allcases['case'+str(i)] = hv_1q_true_i\n",
    "        hv_dict_true_3q_allcases['case'+str(i)] = hv_3q_true_i\n",
    "          \n",
    "    return nfe_array_hv_attained_dict, hv_dict_median_allcases, hv_dict_1q_allcases, hv_dict_3q_allcases, hv_dict_true_median_allcases, hv_dict_true_1q_allcases, hv_dict_true_3q_allcases, nfe_array_i\n",
    "    \n",
    "def plotting_all_cases(nfe_hv_attained_dict, hv_dict_med_allcases, hv_dict_1stq_allcases, hv_dict_3rdq_allcases, hv_dict_true_med_allcases, hv_dict_true_1stq_allcases, hv_dict_true_3rdq_allcases, nfe_array0, mark_colors, alphas, names_cases):\n",
    "    print('Plotting')\n",
    "    plot_fraction_hypervolume_attained(nfe_hv_attained_dict, nfe_array0, mark_colors, names_cases, 'allcases_full')\n",
    "    plot_hypervolume_stats_allcases(hv_dict_med_allcases, hv_dict_1stq_allcases, hv_dict_3rdq_allcases, nfe_array, mark_colors, alphas, names_cases, 'Hypervolume of Penalized Objectives', 'allcases_full')\n",
    "    plot_hypervolume_stats_allcases(hv_dict_true_med_allcases, hv_dict_true_1stq_allcases, hv_dict_true_3rdq_allcases, nfe_array, mark_colors, alphas, names_cases, 'Hypervolume of True Objectives', 'allcases_true')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Satellite Assigning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Satellite Partitioning Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
